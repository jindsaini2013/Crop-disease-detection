{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:46<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Path to your main dataset folder (update this as needed)\n",
    "dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "\n",
    "\n",
    "# Set the desired image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subfolder and read images\n",
    "for class_name in tqdm(os.listdir(dataset_path), desc=\"Loading Images\"):\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            \n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                images.append(img)\n",
    "                labels.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 7907\n",
      "Number of unique classes: 16\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images) / 255.0  # Normalize image pixel values to [0,1]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total images loaded: {len(images)}\")\n",
    "print(f\"Number of unique classes: {len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in dataset: 7907\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Change this to your actual dataset path\n",
    "dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "\n",
    "# List of image file extensions (you can modify if needed)\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "\n",
    "# Counter\n",
    "total_images = 0\n",
    "\n",
    "# Loop through each folder and count image files\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[1].lower() in image_extensions:\n",
    "            total_images += 1\n",
    "\n",
    "print(f\"Total number of images in dataset: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7zltfGt2Gi2"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVpHJ9wilD1Y",
    "outputId": "35d78e80-38c0-4f4d-afda-6c1157fccd04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6331 images belonging to 16 classes.\n",
      "Found 1576 images belonging to 16 classes.\n",
      "Preprocessed 6331 training and 1576 validation images\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ðŸ”¹ Dataset path\n",
    "dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "batch_size = 32\n",
    "img_size = (224, 224)  # Change if necessary\n",
    "\n",
    "# ðŸ”¹ Data Augmentation & Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed {train_generator.samples} training and {val_generator.samples} validation images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6331 images belonging to 16 classes.\n",
      "Found 1576 images belonging to 16 classes.\n",
      "ðŸ”¹ Phase 1: Training with frozen DenseNet base...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 09:38:13.603976: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-04-09 09:38:16.924209: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f15001480f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-09 09:38:16.924232: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA H100 PCIe MIG 3g.40gb, Compute Capability 9.0\n",
      "2025-04-09 09:38:16.951295: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-09 09:38:17.078539: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-04-09 09:38:17.170223: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - ETA: 0s - loss: 1.2204 - accuracy: 0.8090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 09:39:27.696637: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84835, saving model to best_model.h5\n",
      "264/264 [==============================] - 92s 332ms/step - loss: 1.2204 - accuracy: 0.8090 - val_loss: 0.9556 - val_accuracy: 0.8484 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.9313 - accuracy: 0.8664\n",
      "Epoch 2: val_accuracy improved from 0.84835 to 0.87754, saving model to best_model.h5\n",
      "264/264 [==============================] - 91s 344ms/step - loss: 0.9313 - accuracy: 0.8664 - val_loss: 0.8741 - val_accuracy: 0.8775 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.8572 - accuracy: 0.8746\n",
      "Epoch 3: val_accuracy did not improve from 0.87754\n",
      "264/264 [==============================] - 87s 329ms/step - loss: 0.8572 - accuracy: 0.8746 - val_loss: 0.9044 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.8839\n",
      "Epoch 4: val_accuracy did not improve from 0.87754\n",
      "264/264 [==============================] - 87s 330ms/step - loss: 0.7668 - accuracy: 0.8839 - val_loss: 0.7521 - val_accuracy: 0.8763 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.8883\n",
      "Epoch 5: val_accuracy did not improve from 0.87754\n",
      "264/264 [==============================] - 88s 333ms/step - loss: 0.7238 - accuracy: 0.8883 - val_loss: 0.7438 - val_accuracy: 0.8706 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.8916\n",
      "Epoch 6: val_accuracy did not improve from 0.87754\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.6772 - accuracy: 0.8916 - val_loss: 0.7501 - val_accuracy: 0.8693 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.6267 - accuracy: 0.9016\n",
      "Epoch 7: val_accuracy improved from 0.87754 to 0.89213, saving model to best_model.h5\n",
      "264/264 [==============================] - 87s 329ms/step - loss: 0.6267 - accuracy: 0.9016 - val_loss: 0.6067 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.8972\n",
      "Epoch 8: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 86s 325ms/step - loss: 0.5896 - accuracy: 0.8972 - val_loss: 0.7039 - val_accuracy: 0.8699 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.8942\n",
      "Epoch 9: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 87s 331ms/step - loss: 0.6003 - accuracy: 0.8942 - val_loss: 0.5915 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.8965\n",
      "Epoch 10: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 88s 335ms/step - loss: 0.5719 - accuracy: 0.8965 - val_loss: 0.5781 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.9079\n",
      "Epoch 11: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 88s 333ms/step - loss: 0.5275 - accuracy: 0.9079 - val_loss: 0.5670 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.8976\n",
      "Epoch 12: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 88s 334ms/step - loss: 0.5280 - accuracy: 0.8976 - val_loss: 0.5639 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.9003\n",
      "Epoch 13: val_accuracy did not improve from 0.89213\n",
      "264/264 [==============================] - 88s 334ms/step - loss: 0.5171 - accuracy: 0.9003 - val_loss: 0.6334 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5068 - accuracy: 0.9046\n",
      "Epoch 14: val_accuracy improved from 0.89213 to 0.89467, saving model to best_model.h5\n",
      "264/264 [==============================] - 89s 337ms/step - loss: 0.5068 - accuracy: 0.9046 - val_loss: 0.5103 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8997\n",
      "Epoch 15: val_accuracy did not improve from 0.89467\n",
      "264/264 [==============================] - 86s 326ms/step - loss: 0.5081 - accuracy: 0.8997 - val_loss: 0.5181 - val_accuracy: 0.8921 - lr: 0.0010\n",
      "ðŸ”¹ Phase 2: Fine-tuning the DenseNet...\n",
      "Epoch 16/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 10:01:09.764395: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264/264 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.8790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 10:02:34.364584: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: val_accuracy improved from 0.89467 to 0.89530, saving model to best_model.h5\n",
      "264/264 [==============================] - 101s 344ms/step - loss: 0.5411 - accuracy: 0.8790 - val_loss: 0.4678 - val_accuracy: 0.8953 - lr: 8.1193e-04\n",
      "Epoch 17/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.9164\n",
      "Epoch 17: val_accuracy improved from 0.89530 to 0.91371, saving model to best_model.h5\n",
      "264/264 [==============================] - 88s 334ms/step - loss: 0.4098 - accuracy: 0.9164 - val_loss: 0.4304 - val_accuracy: 0.9137 - lr: 7.7567e-04\n",
      "Epoch 18/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.9259\n",
      "Epoch 18: val_accuracy did not improve from 0.91371\n",
      "264/264 [==============================] - 87s 332ms/step - loss: 0.3612 - accuracy: 0.9259 - val_loss: 0.4503 - val_accuracy: 0.9042 - lr: 7.3720e-04\n",
      "Epoch 19/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.9305\n",
      "Epoch 19: val_accuracy improved from 0.91371 to 0.92576, saving model to best_model.h5\n",
      "264/264 [==============================] - 87s 331ms/step - loss: 0.3402 - accuracy: 0.9305 - val_loss: 0.3611 - val_accuracy: 0.9258 - lr: 6.9682e-04\n",
      "Epoch 20/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.9403\n",
      "Epoch 20: val_accuracy improved from 0.92576 to 0.92640, saving model to best_model.h5\n",
      "264/264 [==============================] - 88s 334ms/step - loss: 0.3012 - accuracy: 0.9403 - val_loss: 0.3520 - val_accuracy: 0.9264 - lr: 6.5485e-04\n",
      "Epoch 21/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.9409\n",
      "Epoch 21: val_accuracy improved from 0.92640 to 0.93274, saving model to best_model.h5\n",
      "264/264 [==============================] - 88s 333ms/step - loss: 0.2884 - accuracy: 0.9409 - val_loss: 0.3313 - val_accuracy: 0.9327 - lr: 6.1165e-04\n",
      "Epoch 22/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9491\n",
      "Epoch 22: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 89s 339ms/step - loss: 0.2535 - accuracy: 0.9491 - val_loss: 0.3388 - val_accuracy: 0.9321 - lr: 5.6755e-04\n",
      "Epoch 23/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9512\n",
      "Epoch 23: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 88s 331ms/step - loss: 0.2355 - accuracy: 0.9512 - val_loss: 0.3001 - val_accuracy: 0.9220 - lr: 5.2291e-04\n",
      "Epoch 24/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.9553\n",
      "Epoch 24: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 88s 332ms/step - loss: 0.2168 - accuracy: 0.9553 - val_loss: 0.3304 - val_accuracy: 0.9245 - lr: 4.7809e-04\n",
      "Epoch 25/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9618\n",
      "Epoch 25: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 89s 335ms/step - loss: 0.1939 - accuracy: 0.9618 - val_loss: 0.3477 - val_accuracy: 0.9258 - lr: 4.3345e-04\n",
      "Epoch 26/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9664\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 7.787015638314188e-05.\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 87s 330ms/step - loss: 0.1756 - accuracy: 0.9664 - val_loss: 0.3327 - val_accuracy: 0.9270 - lr: 7.7870e-05\n",
      "Epoch 27/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9695\n",
      "Epoch 27: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 88s 333ms/step - loss: 0.1610 - accuracy: 0.9695 - val_loss: 0.3778 - val_accuracy: 0.9118 - lr: 3.4615e-04\n",
      "Epoch 28/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9700\n",
      "Epoch 28: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 88s 332ms/step - loss: 0.1526 - accuracy: 0.9700 - val_loss: 0.3864 - val_accuracy: 0.9150 - lr: 3.0418e-04\n",
      "Epoch 29/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9709\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 5.2760518155992034e-05.\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 89s 336ms/step - loss: 0.1419 - accuracy: 0.9709 - val_loss: 0.3517 - val_accuracy: 0.9289 - lr: 5.2761e-05\n",
      "Epoch 30/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9747\n",
      "Epoch 30: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 87s 331ms/step - loss: 0.1344 - accuracy: 0.9747 - val_loss: 0.3861 - val_accuracy: 0.9137 - lr: 2.2533e-04\n",
      "Epoch 31/40\n",
      "264/264 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.9779Restoring model weights from the end of the best epoch: 21.\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.93274\n",
      "264/264 [==============================] - 87s 331ms/step - loss: 0.1189 - accuracy: 0.9779 - val_loss: 0.5015 - val_accuracy: 0.9061 - lr: 1.8907e-04\n",
      "Epoch 31: early stopping\n",
      "âœ… Final model saved as 'crop_disease_model_final.h5'\n"
     ]
    }
   ],
   "source": [
    "# âœ… Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# âœ… Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# âœ… Define dataset path\n",
    "dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "\n",
    "# âœ… Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# âœ… Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=24,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=24,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# âœ… Load DenseNet121 base\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base\n",
    "\n",
    "# âœ… Custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.0005))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "# âœ… Build model\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# âœ… Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# âœ… Callbacks\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# âœ… PHASE 1: Train with frozen base\n",
    "print(\"ðŸ”¹ Phase 1: Training with frozen DenseNet base...\")\n",
    "initial_epochs = 15\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# âœ… PHASE 2: Fine-tuning\n",
    "print(\"ðŸ”¹ Phase 2: Fine-tuning the DenseNet...\")\n",
    "\n",
    "# Unfreeze last 80 layers\n",
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-80:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-6),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Optional: Cosine learning rate schedule\n",
    "def cosine_decay_with_warmup(epoch):\n",
    "    warmup_epochs = 5\n",
    "    total_epochs = 40\n",
    "    warmup_lr = 1e-5\n",
    "    base_lr = 1e-3\n",
    "    min_lr = 1e-6\n",
    "\n",
    "    if epoch < warmup_epochs:\n",
    "        return warmup_lr + (base_lr - warmup_lr) * (epoch / warmup_epochs)\n",
    "    \n",
    "    progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
    "    return min_lr + 0.5 * (base_lr - min_lr) * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(cosine_decay_with_warmup)\n",
    "fine_tuning_callbacks = callbacks + [lr_scheduler]\n",
    "\n",
    "# Fine-tune model\n",
    "total_epochs = 40\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs,\n",
    "    callbacks=fine_tuning_callbacks\n",
    ")\n",
    "\n",
    "# âœ… Save final model\n",
    "model.save(\"crop_disease_model_final.h5\")\n",
    "print(\"Final model saved as 'crop_disease_model_final.h5'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation directories already exist. Skipping split.\n",
      "Found 6320 images belonging to 18 classes.\n",
      "Found 1587 images belonging to 18 classes.\n",
      "Found 6320 train images belonging to 18 classes.\n",
      "Found 1587 validation images belonging to 18 classes.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_6 (Rescaling)        (None, 224, 224, 3)  0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_3 (Normalization  (None, 224, 224, 3)  7          ['rescaling_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rescaling_7 (Rescaling)        (None, 224, 224, 3)  0           ['normalization_3[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['rescaling_7[0][0]']            \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 1280)        0           ['top_activation[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 512)          655872      ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 512)         2048        ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 512)          0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 18)           9234        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,716,725\n",
      "Trainable params: 666,130\n",
      "Non-trainable params: 4,050,595\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "ðŸ”¹ Phase 1: EfficientNetB0 - Frozen base\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 13:29:30.855120: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 3.2558 - accuracy: 0.1764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 13:30:43.483371: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.13967, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 83s 407ms/step - loss: 3.2558 - accuracy: 0.1764 - val_loss: 3.0304 - val_accuracy: 0.1397 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.8555 - accuracy: 0.2184\n",
      "Epoch 2: val_accuracy improved from 0.13967 to 0.16837, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 2.8555 - accuracy: 0.2184 - val_loss: 3.2104 - val_accuracy: 0.1684 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.6680 - accuracy: 0.2281\n",
      "Epoch 3: val_accuracy did not improve from 0.16837\n",
      "197/197 [==============================] - 79s 399ms/step - loss: 2.6680 - accuracy: 0.2281 - val_loss: 5.9002 - val_accuracy: 0.0593 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.5198 - accuracy: 0.2471\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.16837 to 0.24936, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 79s 400ms/step - loss: 2.5198 - accuracy: 0.2471 - val_loss: 3.4440 - val_accuracy: 0.2494 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.4154 - accuracy: 0.2621\n",
      "Epoch 5: val_accuracy did not improve from 0.24936\n",
      "197/197 [==============================] - 78s 397ms/step - loss: 2.4154 - accuracy: 0.2621 - val_loss: 2.5718 - val_accuracy: 0.2003 - lr: 2.0000e-04\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.3897 - accuracy: 0.2724\n",
      "Epoch 6: val_accuracy improved from 0.24936 to 0.37054, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 2.3897 - accuracy: 0.2724 - val_loss: 2.4111 - val_accuracy: 0.3705 - lr: 2.0000e-04\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.3606 - accuracy: 0.2732\n",
      "Epoch 7: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 397ms/step - loss: 2.3606 - accuracy: 0.2732 - val_loss: 3.0952 - val_accuracy: 0.1849 - lr: 2.0000e-04\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.3435 - accuracy: 0.2761\n",
      "Epoch 8: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 77s 389ms/step - loss: 2.3435 - accuracy: 0.2761 - val_loss: 2.5309 - val_accuracy: 0.2168 - lr: 2.0000e-04\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.3177 - accuracy: 0.2869\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 2.3177 - accuracy: 0.2869 - val_loss: 2.6926 - val_accuracy: 0.2315 - lr: 2.0000e-04\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2987 - accuracy: 0.2882\n",
      "Epoch 10: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 2.2987 - accuracy: 0.2882 - val_loss: 2.2559 - val_accuracy: 0.2066 - lr: 4.0000e-05\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2834 - accuracy: 0.2950\n",
      "Epoch 11: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 2.2834 - accuracy: 0.2950 - val_loss: 2.2625 - val_accuracy: 0.2564 - lr: 4.0000e-05\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2826 - accuracy: 0.2934\n",
      "Epoch 12: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 2.2826 - accuracy: 0.2934 - val_loss: 2.1505 - val_accuracy: 0.2934 - lr: 4.0000e-05\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2504 - accuracy: 0.3025\n",
      "Epoch 13: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 2.2504 - accuracy: 0.3025 - val_loss: 2.1388 - val_accuracy: 0.3642 - lr: 4.0000e-05\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2697 - accuracy: 0.2894\n",
      "Epoch 14: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 79s 403ms/step - loss: 2.2697 - accuracy: 0.2894 - val_loss: 2.8057 - val_accuracy: 0.2283 - lr: 4.0000e-05\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2587 - accuracy: 0.2987\n",
      "Epoch 15: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 394ms/step - loss: 2.2587 - accuracy: 0.2987 - val_loss: 2.3436 - val_accuracy: 0.2800 - lr: 4.0000e-05\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2589 - accuracy: 0.2942\n",
      "Epoch 16: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 2.2589 - accuracy: 0.2942 - val_loss: 2.1334 - val_accuracy: 0.3061 - lr: 4.0000e-05\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2452 - accuracy: 0.3030\n",
      "Epoch 17: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 77s 389ms/step - loss: 2.2452 - accuracy: 0.3030 - val_loss: 2.1608 - val_accuracy: 0.3578 - lr: 4.0000e-05\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2450 - accuracy: 0.2977\n",
      "Epoch 18: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 2.2450 - accuracy: 0.2977 - val_loss: 2.1679 - val_accuracy: 0.3182 - lr: 4.0000e-05\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2328 - accuracy: 0.3009\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 77s 392ms/step - loss: 2.2328 - accuracy: 0.3009 - val_loss: 2.1983 - val_accuracy: 0.3578 - lr: 4.0000e-05\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 2.2357 - accuracy: 0.3022\n",
      "Epoch 20: val_accuracy did not improve from 0.37054\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 2.2357 - accuracy: 0.3022 - val_loss: 2.2849 - val_accuracy: 0.2621 - lr: 8.0000e-06\n",
      "\n",
      "Phase 1 Best Validation Accuracy: 0.3705 at epoch 6\n",
      "Loading best weights from Phase 1...\n",
      "\n",
      "ðŸ”¹ Phase 2: EfficientNetB0 - Fine-tuning\n",
      "Unfreezing the top 40 layers of the base model.\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_6 (Rescaling)        (None, 224, 224, 3)  0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " normalization_3 (Normalization  (None, 224, 224, 3)  7          ['rescaling_6[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " rescaling_7 (Rescaling)        (None, 224, 224, 3)  0           ['normalization_3[0][0]']        \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding2D)  (None, 225, 225, 3)  0           ['rescaling_7[0][0]']            \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)             (None, 112, 112, 32  864         ['stem_conv_pad[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalization)   (None, 112, 112, 32  128         ['stem_conv[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " stem_activation (Activation)   (None, 112, 112, 32  0           ['stem_bn[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseConv2  (None, 112, 112, 32  288        ['stem_activation[0][0]']        \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormalization  (None, 112, 112, 32  128        ['block1a_dwconv[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_activation (Activation  (None, 112, 112, 32  0          ['block1a_bn[0][0]']             \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (GlobalAver  (None, 32)          0           ['block1a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshape)   (None, 1, 1, 32)     0           ['block1a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)     (None, 1, 1, 8)      264         ['block1a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)     (None, 1, 1, 32)     288         ['block1a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multiply)   (None, 112, 112, 32  0           ['block1a_activation[0][0]',     \n",
      "                                )                                 'block1a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv2D)  (None, 112, 112, 16  512         ['block1a_se_excite[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchNorma  (None, 112, 112, 16  64         ['block1a_project_conv[0][0]']   \n",
      " lization)                      )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2D)   (None, 112, 112, 96  1536        ['block1a_project_bn[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNormal  (None, 112, 112, 96  384        ['block2a_expand_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_expand_activation (Act  (None, 112, 112, 96  0          ['block2a_expand_bn[0][0]']      \n",
      " ivation)                       )                                                                 \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPaddin  (None, 113, 113, 96  0          ['block2a_expand_activation[0][0]\n",
      " g2D)                           )                                ']                               \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseConv2  (None, 56, 56, 96)  864         ['block2a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormalization  (None, 56, 56, 96)  384         ['block2a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_activation (Activation  (None, 56, 56, 96)  0           ['block2a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (GlobalAver  (None, 96)          0           ['block2a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshape)   (None, 1, 1, 96)     0           ['block2a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)     (None, 1, 1, 4)      388         ['block2a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)     (None, 1, 1, 96)     480         ['block2a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multiply)   (None, 56, 56, 96)   0           ['block2a_activation[0][0]',     \n",
      "                                                                  'block2a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv2D)  (None, 56, 56, 24)   2304        ['block2a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block2b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_expand_activation (Act  (None, 56, 56, 144)  0          ['block2b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseConv2  (None, 56, 56, 144)  1296       ['block2b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormalization  (None, 56, 56, 144)  576        ['block2b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_activation (Activation  (None, 56, 56, 144)  0          ['block2b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (GlobalAver  (None, 144)         0           ['block2b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block2b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block2b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block2b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multiply)   (None, 56, 56, 144)  0           ['block2b_activation[0][0]',     \n",
      "                                                                  'block2b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv2D)  (None, 56, 56, 24)   3456        ['block2b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchNorma  (None, 56, 56, 24)  96          ['block2b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)         (None, 56, 56, 24)   0           ['block2b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block2b_add (Add)              (None, 56, 56, 24)   0           ['block2b_drop[0][0]',           \n",
      "                                                                  'block2a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2D)   (None, 56, 56, 144)  3456        ['block2b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNormal  (None, 56, 56, 144)  576        ['block3a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_expand_activation (Act  (None, 56, 56, 144)  0          ['block3a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPaddin  (None, 59, 59, 144)  0          ['block3a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseConv2  (None, 28, 28, 144)  3600       ['block3a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormalization  (None, 28, 28, 144)  576        ['block3a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_activation (Activation  (None, 28, 28, 144)  0          ['block3a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (GlobalAver  (None, 144)         0           ['block3a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshape)   (None, 1, 1, 144)    0           ['block3a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)     (None, 1, 1, 6)      870         ['block3a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)     (None, 1, 1, 144)    1008        ['block3a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multiply)   (None, 28, 28, 144)  0           ['block3a_activation[0][0]',     \n",
      "                                                                  'block3a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv2D)  (None, 28, 28, 40)   5760        ['block3a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block3b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_expand_activation (Act  (None, 28, 28, 240)  0          ['block3b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseConv2  (None, 28, 28, 240)  6000       ['block3b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormalization  (None, 28, 28, 240)  960        ['block3b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_activation (Activation  (None, 28, 28, 240)  0          ['block3b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (GlobalAver  (None, 240)         0           ['block3b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block3b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block3b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block3b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multiply)   (None, 28, 28, 240)  0           ['block3b_activation[0][0]',     \n",
      "                                                                  'block3b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv2D)  (None, 28, 28, 40)   9600        ['block3b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchNorma  (None, 28, 28, 40)  160         ['block3b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)         (None, 28, 28, 40)   0           ['block3b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block3b_add (Add)              (None, 28, 28, 40)   0           ['block3b_drop[0][0]',           \n",
      "                                                                  'block3a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2D)   (None, 28, 28, 240)  9600        ['block3b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNormal  (None, 28, 28, 240)  960        ['block4a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_expand_activation (Act  (None, 28, 28, 240)  0          ['block4a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPaddin  (None, 29, 29, 240)  0          ['block4a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseConv2  (None, 14, 14, 240)  2160       ['block4a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormalization  (None, 14, 14, 240)  960        ['block4a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_activation (Activation  (None, 14, 14, 240)  0          ['block4a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (GlobalAver  (None, 240)         0           ['block4a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshape)   (None, 1, 1, 240)    0           ['block4a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)     (None, 1, 1, 10)     2410        ['block4a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)     (None, 1, 1, 240)    2640        ['block4a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multiply)   (None, 14, 14, 240)  0           ['block4a_activation[0][0]',     \n",
      "                                                                  'block4a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv2D)  (None, 14, 14, 80)   19200       ['block4a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_expand_activation (Act  (None, 14, 14, 480)  0          ['block4b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_activation (Activation  (None, 14, 14, 480)  0          ['block4b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (GlobalAver  (None, 480)         0           ['block4b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4b_activation[0][0]',     \n",
      "                                                                  'block4b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)         (None, 14, 14, 80)   0           ['block4b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4b_add (Add)              (None, 14, 14, 80)   0           ['block4b_drop[0][0]',           \n",
      "                                                                  'block4a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block4c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_expand_activation (Act  (None, 14, 14, 480)  0          ['block4c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseConv2  (None, 14, 14, 480)  4320       ['block4c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block4c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_activation (Activation  (None, 14, 14, 480)  0          ['block4c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (GlobalAver  (None, 480)         0           ['block4c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block4c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block4c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block4c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block4c_activation[0][0]',     \n",
      "                                                                  'block4c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv2D)  (None, 14, 14, 80)   38400       ['block4c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchNorma  (None, 14, 14, 80)  320         ['block4c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)         (None, 14, 14, 80)   0           ['block4c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block4c_add (Add)              (None, 14, 14, 80)   0           ['block4c_drop[0][0]',           \n",
      "                                                                  'block4b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2D)   (None, 14, 14, 480)  38400       ['block4c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNormal  (None, 14, 14, 480)  1920       ['block5a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_expand_activation (Act  (None, 14, 14, 480)  0          ['block5a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseConv2  (None, 14, 14, 480)  12000      ['block5a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormalization  (None, 14, 14, 480)  1920       ['block5a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_activation (Activation  (None, 14, 14, 480)  0          ['block5a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (GlobalAver  (None, 480)         0           ['block5a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshape)   (None, 1, 1, 480)    0           ['block5a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)     (None, 1, 1, 20)     9620        ['block5a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)     (None, 1, 1, 480)    10080       ['block5a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multiply)   (None, 14, 14, 480)  0           ['block5a_activation[0][0]',     \n",
      "                                                                  'block5a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv2D)  (None, 14, 14, 112)  53760       ['block5a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_expand_activation (Act  (None, 14, 14, 672)  0          ['block5b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_activation (Activation  (None, 14, 14, 672)  0          ['block5b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5b_activation[0][0]',     \n",
      "                                                                  'block5b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)         (None, 14, 14, 112)  0           ['block5b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5b_add (Add)              (None, 14, 14, 112)  0           ['block5b_drop[0][0]',           \n",
      "                                                                  'block5a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block5c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_expand_activation (Act  (None, 14, 14, 672)  0          ['block5c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseConv2  (None, 14, 14, 672)  16800      ['block5c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormalization  (None, 14, 14, 672)  2688       ['block5c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_activation (Activation  (None, 14, 14, 672)  0          ['block5c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multiply)   (None, 14, 14, 672)  0           ['block5c_activation[0][0]',     \n",
      "                                                                  'block5c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv2D)  (None, 14, 14, 112)  75264       ['block5c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchNorma  (None, 14, 14, 112)  448        ['block5c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)         (None, 14, 14, 112)  0           ['block5c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block5c_add (Add)              (None, 14, 14, 112)  0           ['block5c_drop[0][0]',           \n",
      "                                                                  'block5b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2D)   (None, 14, 14, 672)  75264       ['block5c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNormal  (None, 14, 14, 672)  2688       ['block6a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_expand_activation (Act  (None, 14, 14, 672)  0          ['block6a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPaddin  (None, 17, 17, 672)  0          ['block6a_expand_activation[0][0]\n",
      " g2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseConv2  (None, 7, 7, 672)   16800       ['block6a_dwconv_pad[0][0]']     \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormalization  (None, 7, 7, 672)   2688        ['block6a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_activation (Activation  (None, 7, 7, 672)   0           ['block6a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multiply)   (None, 7, 7, 672)    0           ['block6a_activation[0][0]',     \n",
      "                                                                  'block6a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv2D)  (None, 7, 7, 192)    129024      ['block6a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6b_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6b_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_activation (Activation  (None, 7, 7, 1152)  0           ['block6b_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6b_activation[0][0]',     \n",
      "                                                                  'block6b_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6b_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6b_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)         (None, 7, 7, 192)    0           ['block6b_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6b_add (Add)              (None, 7, 7, 192)    0           ['block6b_drop[0][0]',           \n",
      "                                                                  'block6a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6c_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6c_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_activation (Activation  (None, 7, 7, 1152)  0           ['block6c_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6c_activation[0][0]',     \n",
      "                                                                  'block6c_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6c_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6c_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)         (None, 7, 7, 192)    0           ['block6c_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6c_add (Add)              (None, 7, 7, 192)    0           ['block6c_drop[0][0]',           \n",
      "                                                                  'block6b_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_expand_activation (Act  (None, 7, 7, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  28800       ['block6d_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block6d_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_activation (Activation  (None, 7, 7, 1152)  0           ['block6d_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block6d_activation[0][0]',     \n",
      "                                                                  'block6d_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv2D)  (None, 7, 7, 192)    221184      ['block6d_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchNorma  (None, 7, 7, 192)   768         ['block6d_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)         (None, 7, 7, 192)    0           ['block6d_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " block6d_add (Add)              (None, 7, 7, 192)    0           ['block6d_drop[0][0]',           \n",
      "                                                                  'block6c_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2D)   (None, 7, 7, 1152)   221184      ['block6d_add[0][0]']            \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNormal  (None, 7, 7, 1152)  4608        ['block7a_expand_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_expand_activation (Act  (None, 7, 7, 1152)  0           ['block7a_expand_bn[0][0]']      \n",
      " ivation)                                                                                         \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseConv2  (None, 7, 7, 1152)  10368       ['block7a_expand_activation[0][0]\n",
      " D)                                                              ']                               \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormalization  (None, 7, 7, 1152)  4608        ['block7a_dwconv[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_activation (Activation  (None, 7, 7, 1152)  0           ['block7a_bn[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (GlobalAver  (None, 1152)        0           ['block7a_activation[0][0]']     \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block7a_se_squeeze[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block7a_se_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block7a_se_reduce[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multiply)   (None, 7, 7, 1152)   0           ['block7a_activation[0][0]',     \n",
      "                                                                  'block7a_se_expand[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv2D)  (None, 7, 7, 320)    368640      ['block7a_se_excite[0][0]']      \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchNorma  (None, 7, 7, 320)   1280        ['block7a_project_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)              (None, 7, 7, 1280)   409600      ['block7a_project_bn[0][0]']     \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization)    (None, 7, 7, 1280)   5120        ['top_conv[0][0]']               \n",
      "                                                                                                  \n",
      " top_activation (Activation)    (None, 7, 7, 1280)   0           ['top_bn[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 1280)        0           ['top_activation[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 512)          655872      ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 512)         2048        ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 512)          0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 18)           9234        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,716,725\n",
      "Trainable params: 2,745,666\n",
      "Non-trainable params: 1,971,059\n",
      "__________________________________________________________________________________________________\n",
      "Starting fine-tuning for 40 epochs...\n",
      "Epoch 21/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 13:55:35.860880: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2025-04-09 13:55:40.810560: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:1014] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 2.3342 - accuracy: 0.3962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 13:57:05.883541: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: val_accuracy improved from -inf to 0.08801, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 100s 438ms/step - loss: 2.3342 - accuracy: 0.3962 - val_loss: 7.9917 - val_accuracy: 0.0880 - lr: 1.0000e-05\n",
      "Epoch 22/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 1.3569 - accuracy: 0.6215\n",
      "Epoch 22: val_accuracy improved from 0.08801 to 0.16263, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 428ms/step - loss: 1.3569 - accuracy: 0.6215 - val_loss: 4.2871 - val_accuracy: 0.1626 - lr: 1.0000e-05\n",
      "Epoch 23/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 1.0138 - accuracy: 0.7106\n",
      "Epoch 23: val_accuracy improved from 0.16263 to 0.52934, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 86s 434ms/step - loss: 1.0138 - accuracy: 0.7106 - val_loss: 1.6617 - val_accuracy: 0.5293 - lr: 1.0000e-05\n",
      "Epoch 24/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.7506\n",
      "Epoch 24: val_accuracy improved from 0.52934 to 0.80612, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 426ms/step - loss: 0.8478 - accuracy: 0.7506 - val_loss: 0.7287 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
      "Epoch 25/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.7621 - accuracy: 0.7834\n",
      "Epoch 25: val_accuracy improved from 0.80612 to 0.86224, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 86s 438ms/step - loss: 0.7621 - accuracy: 0.7834 - val_loss: 0.5457 - val_accuracy: 0.8622 - lr: 1.0000e-05\n",
      "Epoch 26/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.7980\n",
      "Epoch 26: val_accuracy improved from 0.86224 to 0.86798, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 427ms/step - loss: 0.7034 - accuracy: 0.7980 - val_loss: 0.5105 - val_accuracy: 0.8680 - lr: 1.0000e-05\n",
      "Epoch 27/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6557 - accuracy: 0.8117\n",
      "Epoch 27: val_accuracy did not improve from 0.86798\n",
      "197/197 [==============================] - 84s 425ms/step - loss: 0.6557 - accuracy: 0.8117 - val_loss: 0.4978 - val_accuracy: 0.8667 - lr: 1.0000e-05\n",
      "Epoch 28/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6340 - accuracy: 0.8190\n",
      "Epoch 28: val_accuracy improved from 0.86798 to 0.88138, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 85s 431ms/step - loss: 0.6340 - accuracy: 0.8190 - val_loss: 0.4657 - val_accuracy: 0.8814 - lr: 1.0000e-05\n",
      "Epoch 29/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6010 - accuracy: 0.8290\n",
      "Epoch 29: val_accuracy improved from 0.88138 to 0.88712, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 425ms/step - loss: 0.6010 - accuracy: 0.8290 - val_loss: 0.4404 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 30/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.8402\n",
      "Epoch 30: val_accuracy improved from 0.88712 to 0.89477, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 428ms/step - loss: 0.5770 - accuracy: 0.8402 - val_loss: 0.4246 - val_accuracy: 0.8948 - lr: 1.0000e-05\n",
      "Epoch 31/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.8476\n",
      "Epoch 31: val_accuracy did not improve from 0.89477\n",
      "197/197 [==============================] - 84s 427ms/step - loss: 0.5423 - accuracy: 0.8476 - val_loss: 0.4232 - val_accuracy: 0.8897 - lr: 1.0000e-05\n",
      "Epoch 32/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.8576\n",
      "Epoch 32: val_accuracy did not improve from 0.89477\n",
      "197/197 [==============================] - 85s 432ms/step - loss: 0.5084 - accuracy: 0.8576 - val_loss: 0.4173 - val_accuracy: 0.8916 - lr: 1.0000e-05\n",
      "Epoch 33/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8599\n",
      "Epoch 33: val_accuracy did not improve from 0.89477\n",
      "197/197 [==============================] - 84s 427ms/step - loss: 0.5031 - accuracy: 0.8599 - val_loss: 0.4198 - val_accuracy: 0.8871 - lr: 1.0000e-05\n",
      "Epoch 34/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.8639\n",
      "Epoch 34: val_accuracy improved from 0.89477 to 0.89668, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 87s 440ms/step - loss: 0.4981 - accuracy: 0.8639 - val_loss: 0.4040 - val_accuracy: 0.8967 - lr: 1.0000e-05\n",
      "Epoch 35/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8653\n",
      "Epoch 35: val_accuracy improved from 0.89668 to 0.90051, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 83s 423ms/step - loss: 0.4869 - accuracy: 0.8653 - val_loss: 0.3878 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 36/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.8696\n",
      "Epoch 36: val_accuracy did not improve from 0.90051\n",
      "197/197 [==============================] - 84s 424ms/step - loss: 0.4755 - accuracy: 0.8696 - val_loss: 0.3854 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 37/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.8763\n",
      "Epoch 37: val_accuracy improved from 0.90051 to 0.90242, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 86s 435ms/step - loss: 0.4639 - accuracy: 0.8763 - val_loss: 0.3885 - val_accuracy: 0.9024 - lr: 1.0000e-05\n",
      "Epoch 38/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.8764\n",
      "Epoch 38: val_accuracy did not improve from 0.90242\n",
      "197/197 [==============================] - 83s 424ms/step - loss: 0.4615 - accuracy: 0.8764 - val_loss: 0.3896 - val_accuracy: 0.9005 - lr: 1.0000e-05\n",
      "Epoch 39/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4574 - accuracy: 0.8774\n",
      "Epoch 39: val_accuracy improved from 0.90242 to 0.90306, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 426ms/step - loss: 0.4574 - accuracy: 0.8774 - val_loss: 0.3749 - val_accuracy: 0.9031 - lr: 1.0000e-05\n",
      "Epoch 40/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.8822\n",
      "Epoch 40: val_accuracy did not improve from 0.90306\n",
      "197/197 [==============================] - 84s 427ms/step - loss: 0.4364 - accuracy: 0.8822 - val_loss: 0.3808 - val_accuracy: 0.9024 - lr: 1.0000e-05\n",
      "Epoch 41/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8836\n",
      "Epoch 41: val_accuracy improved from 0.90306 to 0.90689, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 85s 432ms/step - loss: 0.4407 - accuracy: 0.8836 - val_loss: 0.3668 - val_accuracy: 0.9069 - lr: 1.0000e-05\n",
      "Epoch 42/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8845\n",
      "Epoch 42: val_accuracy improved from 0.90689 to 0.91008, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 424ms/step - loss: 0.4407 - accuracy: 0.8845 - val_loss: 0.3683 - val_accuracy: 0.9101 - lr: 1.0000e-05\n",
      "Epoch 43/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4235 - accuracy: 0.8887\n",
      "Epoch 43: val_accuracy improved from 0.91008 to 0.91263, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 86s 434ms/step - loss: 0.4235 - accuracy: 0.8887 - val_loss: 0.3678 - val_accuracy: 0.9126 - lr: 1.0000e-05\n",
      "Epoch 44/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8872\n",
      "Epoch 44: val_accuracy improved from 0.91263 to 0.91327, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 83s 421ms/step - loss: 0.4256 - accuracy: 0.8872 - val_loss: 0.3643 - val_accuracy: 0.9133 - lr: 1.0000e-05\n",
      "Epoch 45/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.8966\n",
      "Epoch 45: val_accuracy improved from 0.91327 to 0.91645, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 424ms/step - loss: 0.4012 - accuracy: 0.8966 - val_loss: 0.3600 - val_accuracy: 0.9165 - lr: 1.0000e-05\n",
      "Epoch 46/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.8958\n",
      "Epoch 46: val_accuracy improved from 0.91645 to 0.92092, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 85s 431ms/step - loss: 0.4068 - accuracy: 0.8958 - val_loss: 0.3455 - val_accuracy: 0.9209 - lr: 1.0000e-05\n",
      "Epoch 47/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8920\n",
      "Epoch 47: val_accuracy did not improve from 0.92092\n",
      "197/197 [==============================] - 84s 427ms/step - loss: 0.4085 - accuracy: 0.8920 - val_loss: 0.3478 - val_accuracy: 0.9177 - lr: 1.0000e-05\n",
      "Epoch 48/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.8939\n",
      "Epoch 48: val_accuracy improved from 0.92092 to 0.92793, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 84s 425ms/step - loss: 0.3993 - accuracy: 0.8939 - val_loss: 0.3365 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Epoch 49/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4035 - accuracy: 0.8949\n",
      "Epoch 49: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 83s 421ms/step - loss: 0.4035 - accuracy: 0.8949 - val_loss: 0.3376 - val_accuracy: 0.9228 - lr: 1.0000e-05\n",
      "Epoch 50/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8979\n",
      "Epoch 50: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 85s 430ms/step - loss: 0.3926 - accuracy: 0.8979 - val_loss: 0.3473 - val_accuracy: 0.9247 - lr: 1.0000e-05\n",
      "Epoch 51/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.8999\n",
      "Epoch 51: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 83s 421ms/step - loss: 0.3861 - accuracy: 0.8999 - val_loss: 0.3404 - val_accuracy: 0.9222 - lr: 1.0000e-05\n",
      "Epoch 52/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.9043\n",
      "Epoch 52: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 85s 433ms/step - loss: 0.3789 - accuracy: 0.9043 - val_loss: 0.3314 - val_accuracy: 0.9241 - lr: 1.0000e-05\n",
      "Epoch 53/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3843 - accuracy: 0.8971\n",
      "Epoch 53: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 83s 422ms/step - loss: 0.3843 - accuracy: 0.8971 - val_loss: 0.3317 - val_accuracy: 0.9260 - lr: 1.0000e-05\n",
      "Epoch 54/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3792 - accuracy: 0.9028\n",
      "Epoch 54: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 84s 425ms/step - loss: 0.3792 - accuracy: 0.9028 - val_loss: 0.3408 - val_accuracy: 0.9203 - lr: 1.0000e-05\n",
      "Epoch 55/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3750 - accuracy: 0.9036\n",
      "Epoch 55: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 85s 432ms/step - loss: 0.3750 - accuracy: 0.9036 - val_loss: 0.3275 - val_accuracy: 0.9260 - lr: 1.0000e-05\n",
      "Epoch 56/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3682 - accuracy: 0.9036\n",
      "Epoch 56: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 83s 419ms/step - loss: 0.3682 - accuracy: 0.9036 - val_loss: 0.3252 - val_accuracy: 0.9216 - lr: 1.0000e-05\n",
      "Epoch 57/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3616 - accuracy: 0.9082\n",
      "Epoch 57: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 86s 436ms/step - loss: 0.3616 - accuracy: 0.9082 - val_loss: 0.3139 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Epoch 58/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.9097\n",
      "Epoch 58: val_accuracy did not improve from 0.92793\n",
      "197/197 [==============================] - 84s 425ms/step - loss: 0.3526 - accuracy: 0.9097 - val_loss: 0.3192 - val_accuracy: 0.9209 - lr: 1.0000e-05\n",
      "Epoch 59/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.9106\n",
      "Epoch 59: val_accuracy improved from 0.92793 to 0.93048, saving model to efficientnetb0_best_weights.h5\n",
      "197/197 [==============================] - 86s 436ms/step - loss: 0.3559 - accuracy: 0.9106 - val_loss: 0.3073 - val_accuracy: 0.9305 - lr: 1.0000e-05\n",
      "Epoch 60/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.9098\n",
      "Epoch 60: val_accuracy did not improve from 0.93048\n",
      "197/197 [==============================] - 83s 423ms/step - loss: 0.3454 - accuracy: 0.9098 - val_loss: 0.3265 - val_accuracy: 0.9260 - lr: 1.0000e-05\n",
      "\n",
      "Loading best weights achieved during entire training...\n",
      "\n",
      "Evaluating model with best weights on validation set:\n",
      " 5/49 [==>...........................] - ETA: 1s - loss: 0.2228 - accuracy: 0.9563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 14:52:03.648453: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 8s 169ms/step - loss: 0.3073 - accuracy: 0.9305\n",
      "Validation Loss: 0.3073\n",
      "Validation Accuracy: 0.9305\n",
      "\n",
      "ðŸŽ‰ Target accuracy reached! Final Validation Accuracy: 0.9305\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 245\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider further experimentation (more epochs, different LR, more/less unfrozen layers, stronger augmentation, different model size like B1/B2).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# ðŸ”¹ Save final model (architecture + best weights)\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mefficientnetb0_final_best.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Best model saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficientnetb0_final_best.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "# âœ… EfficientNetB0 Training Script with Improvements for Accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "# Use AdamW for potentially better weight decay handling\n",
    "from tensorflow.keras.optimizers.experimental import AdamW # Or tf.keras.optimizers if using older TF\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil # For splitting data\n",
    "\n",
    "# ðŸ”¹ Set seed for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ðŸ”¹ Dataset path (update this if needed)\n",
    "base_dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "\n",
    "train_dir = os.path.join(base_dataset_path, \"train\")\n",
    "val_dir = os.path.join(base_dataset_path, \"validation\")\n",
    "VAL_SPLIT = 0.2 # Use 20% of data for validation\n",
    "\n",
    "# ðŸ”¹ Helper Function to Split Data (Run this once if needed)\n",
    "def split_data(base_path, train_path, val_path, split_ratio=0.2):\n",
    "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
    "        print(\"Train/Validation directories already exist. Skipping split.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Creating train/validation split ({1-split_ratio:.0%}/{split_ratio:.0%}) in {base_path}...\")\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(base_path):\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        if os.path.isdir(class_dir): # Make sure it's a directory\n",
    "            # Create corresponding directories in train/val\n",
    "            train_class_dir = os.path.join(train_path, class_name)\n",
    "            val_class_dir = os.path.join(val_path, class_name)\n",
    "            os.makedirs(train_class_dir, exist_ok=True)\n",
    "            os.makedirs(val_class_dir, exist_ok=True)\n",
    "\n",
    "            # List images and shuffle\n",
    "            images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
    "            np.random.shuffle(images) # Shuffle in place\n",
    "\n",
    "            # Split files\n",
    "            split_point = int(len(images) * (1 - split_ratio))\n",
    "            train_files = images[:split_point]\n",
    "            val_files = images[split_point:]\n",
    "\n",
    "            # Copy files\n",
    "            for f in train_files:\n",
    "                shutil.copy(os.path.join(class_dir, f), os.path.join(train_class_dir, f))\n",
    "            for f in val_files:\n",
    "                shutil.copy(os.path.join(class_dir, f), os.path.join(val_class_dir, f))\n",
    "    print(\"Data splitting complete.\")\n",
    "\n",
    "# --- Run the data splitting function ---\n",
    "# Important: Make sure your original 'Capstone Dataset' folder only contains class subfolders.\n",
    "# If it already has 'train' and 'validation' subfolders, comment out or skip this call.\n",
    "# Adjust base_dataset_path if 'Capstone Dataset' itself contains the class folders.\n",
    "original_data_path = base_dataset_path # Assumes class folders are directly inside this path\n",
    "split_data(original_data_path, train_dir, val_dir, split_ratio=VAL_SPLIT)\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ðŸ”¹ Data Augmentation & Generators\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32 # Slightly increased batch size, adjust based on GPU memory\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    "    # Removed validation_split as we now have separate directories\n",
    ")\n",
    "\n",
    "# Validation generator ONLY rescales\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, # Use the new train directory\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir, # Use the new validation directory\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE, # Can use larger batch size for validation if memory allows\n",
    "    class_mode='categorical',\n",
    "    shuffle=False # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "# Check number of classes\n",
    "num_classes = train_generator.num_classes\n",
    "print(f\"Found {train_generator.samples} train images belonging to {num_classes} classes.\")\n",
    "print(f\"Found {val_generator.samples} validation images belonging to {num_classes} classes.\")\n",
    "\n",
    "# ðŸ”¹ Load EfficientNetB0\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False  # Freeze base initially\n",
    "\n",
    "# ðŸ”¹ Add classification head (slightly adjusted)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# Consider reducing Dense units if overfitting is suspected, or increasing if underfitting\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x) # Slightly increased L2\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x) # Slightly increased Dropout\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# ðŸ”¹ Compile model for Phase 1\n",
    "# Initial LR can be critical. 1e-3 is common, but 5e-4 might be safer.\n",
    "initial_lr = 1e-3\n",
    "optimizer_phase1 = AdamW(learning_rate=initial_lr, weight_decay=1e-4) # Using AdamW\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase1,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ðŸ”¹ Callbacks\n",
    "# Using the same ReduceLROnPlateau for both phases initially\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "# Increased patience slightly for EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1)\n",
    "# ModelCheckpoint remains crucial\n",
    "model_checkpoint = ModelCheckpoint('efficientnetb0_best_weights.h5', monitor='val_accuracy', save_best_only=True,\n",
    "                                   save_weights_only=True, verbose=1)\n",
    "\n",
    "callbacks_phase1 = [reduce_lr, early_stopping, model_checkpoint]\n",
    "\n",
    "# ðŸ”¹ PHASE 1: Training with frozen base\n",
    "print(\"\\nðŸ”¹ Phase 1: EfficientNetB0 - Frozen base\")\n",
    "initial_epochs = 20 # Increased epochs for initial training\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks_phase1,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Find the epoch with the best validation accuracy in phase 1\n",
    "best_epoch_phase1 = np.argmax(history_phase1.history['val_accuracy'])\n",
    "best_val_acc_phase1 = np.max(history_phase1.history['val_accuracy'])\n",
    "print(f\"\\nPhase 1 Best Validation Accuracy: {best_val_acc_phase1:.4f} at epoch {best_epoch_phase1 + 1}\")\n",
    "\n",
    "# Load the best weights found during Phase 1 before fine-tuning\n",
    "print(\"Loading best weights from Phase 1...\")\n",
    "model.load_weights('efficientnetb0_best_weights.h5')\n",
    "\n",
    "# ðŸ”¹ PHASE 2: Fine-tuning\n",
    "print(\"\\nðŸ”¹ Phase 2: EfficientNetB0 - Fine-tuning\")\n",
    "\n",
    "# Unfreeze some layers - Start with fewer layers\n",
    "# EfficientNetB0 has ~230 layers. Let's unfreeze the last block (approx last 30-40 layers)\n",
    "# Fine-tune this number based on results. More layers = more risk of overfitting.\n",
    "num_layers_to_unfreeze = 40\n",
    "print(f\"Unfreezing the top {num_layers_to_unfreeze} layers of the base model.\")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-num_layers_to_unfreeze]:\n",
    "     # Keep batch norm layers frozen if using them, helps prevent unstable gradients\n",
    "    if not isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Check trainable status\n",
    "#for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name, layer.trainable)\n",
    "\n",
    "\n",
    "# Recompile with a lower LR for fine-tuning\n",
    "fine_tune_lr = 1e-5 # Start with a significantly lower LR for fine-tuning\n",
    "optimizer_phase2 = AdamW(learning_rate=fine_tune_lr, weight_decay=1e-5) # Lower weight decay too\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase2,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary() # Show summary with updated trainable params\n",
    "\n",
    "# Use the same callbacks, but potentially adjust patience if needed\n",
    "# The EarlyStopping callback will continue from where it left off (if not triggered)\n",
    "# ReduceLROnPlateau will also adapt based on the new optimizer and LR\n",
    "callbacks_phase2 = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1), # More patience for fine-tuning LR reduction\n",
    "    EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1), # More patience for fine-tuning stopping\n",
    "    ModelCheckpoint('efficientnetb0_best_weights.h5', monitor='val_accuracy', save_best_only=True,\n",
    "                    save_weights_only=True, verbose=1) # Continue saving best weights\n",
    "]\n",
    "\n",
    "# Train model further with fine-tuning\n",
    "total_epochs = 60 # Increase total epochs\n",
    "fine_tune_epochs = total_epochs - initial_epochs\n",
    "\n",
    "print(f\"Starting fine-tuning for {fine_tune_epochs} epochs...\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs, # Start counting epochs from here\n",
    "    callbacks=callbacks_phase2,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_steps=val_generator.samples // BATCH_SIZE\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Evaluation after Fine-Tuning\n",
    "print(\"\\nLoading best weights achieved during entire training...\")\n",
    "model.load_weights('efficientnetb0_best_weights.h5')\n",
    "\n",
    "print(\"\\nEvaluating model with best weights on validation set:\")\n",
    "loss, accuracy = model.evaluate(val_generator, steps=val_generator.samples // BATCH_SIZE)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "if accuracy >= 0.91:\n",
    "    print(f\"\\nðŸŽ‰ Target accuracy reached! Final Validation Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTarget accuracy of 0.91 not reached. Final Best Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Consider further experimentation (more epochs, different LR, more/less unfrozen layers, stronger augmentation, different model size like B1/B2).\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ Save final model (architecture + best weights)\n",
    "model.save(\"efficientnetb0_final_best.h5\")\n",
    "print(\"\\nâœ… Best model saved as 'efficientnetb0_final_best.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation split (80%/20%) in /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset...\n",
      "  Splitting Potato___Late_Blight: 800 train, 200 val\n",
      "  Splitting Potato___Early_Blight: 200 train, 50 val\n",
      "  Splitting Cotton___Thrip: 139 train, 35 val\n",
      "  Splitting Rice___Brown_Spot: 326 train, 82 val\n",
      "  Splitting Corn___Gray_Leaf_Spot: 410 train, 103 val\n",
      "  Splitting Corn___Common_Rust: 397 train, 100 val\n",
      "  Splitting Corn___Healthy: 788 train, 197 val\n",
      "  Splitting Wheat___Yellow_Rust: 107 train, 27 val\n",
      "  Splitting Rice___Neck_Blast: 615 train, 154 val\n",
      "  Splitting Rice___Leaf_Blast: 569 train, 143 val\n",
      "  Splitting Rice___Healthy: 372 train, 93 val\n",
      "Warning: No images found in /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/train\n",
      "  Splitting Potato___Healthy: 121 train, 31 val\n",
      "  Splitting Corn___Northern_Leaf_Blight: 496 train, 124 val\n",
      "  Splitting Wheat___Healthy: 892 train, 224 val\n",
      "  Splitting Wheat___Brown_Rust: 80 train, 21 val\n",
      "Warning: No images found in /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/validation\n",
      "  Splitting Sugarcane__Red Rot: 8 train, 3 val\n",
      "Data splitting complete.\n",
      "Train data in: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/train\n",
      "Validation data in: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/validation\n",
      "Found 6320 images belonging to 18 classes.\n",
      "Found 1587 images belonging to 18 classes.\n",
      "Found 6320 train images belonging to 18 classes.\n",
      "Found 1587 validation images belonging to 18 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 9s 0us/step\n",
      "\n",
      "--- Model Summary (Phase 1: Frozen Base) ---\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " dense_head (Dense)             (None, 512)          1049088     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " bn_head (BatchNormalization)   (None, 512)          2048        ['dense_head[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_head (Dropout)         (None, 512)          0           ['bn_head[0][0]']                \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 18)           9234        ['dropout_head[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,648,082\n",
      "Trainable params: 1,059,346\n",
      "Non-trainable params: 23,588,736\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "ðŸ”¹ Phase 1: ResNet50 - Frozen base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 12:09:20.309972: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 1.1547 - accuracy: 0.8626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 12:10:54.928191: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92602, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 85s 422ms/step - loss: 1.1547 - accuracy: 0.8626 - val_loss: 0.8467 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.9092\n",
      "Epoch 2: val_accuracy improved from 0.92602 to 0.93941, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 0.7933 - accuracy: 0.9092 - val_loss: 0.6377 - val_accuracy: 0.9394 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.9168\n",
      "Epoch 3: val_accuracy did not improve from 0.93941\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 0.6243 - accuracy: 0.9168 - val_loss: 0.5299 - val_accuracy: 0.9279 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.9189\n",
      "Epoch 4: val_accuracy did not improve from 0.93941\n",
      "197/197 [==============================] - 77s 392ms/step - loss: 0.5274 - accuracy: 0.9189 - val_loss: 0.4937 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4624 - accuracy: 0.9200\n",
      "Epoch 5: val_accuracy did not improve from 0.93941\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.4624 - accuracy: 0.9200 - val_loss: 0.4661 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4321 - accuracy: 0.9176\n",
      "Epoch 6: val_accuracy improved from 0.93941 to 0.94643, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 78s 397ms/step - loss: 0.4321 - accuracy: 0.9176 - val_loss: 0.3602 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.9226\n",
      "Epoch 7: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 79s 402ms/step - loss: 0.3943 - accuracy: 0.9226 - val_loss: 0.4149 - val_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.9230\n",
      "Epoch 8: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 0.3800 - accuracy: 0.9230 - val_loss: 0.3882 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.9259\n",
      "Epoch 9: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 0.3701 - accuracy: 0.9259 - val_loss: 0.3407 - val_accuracy: 0.9330 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.9272\n",
      "Epoch 10: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 79s 402ms/step - loss: 0.3521 - accuracy: 0.9272 - val_loss: 0.3242 - val_accuracy: 0.9388 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.9276\n",
      "Epoch 11: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 78s 399ms/step - loss: 0.3490 - accuracy: 0.9276 - val_loss: 0.3597 - val_accuracy: 0.9209 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9300\n",
      "Epoch 12: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 0.3357 - accuracy: 0.9300 - val_loss: 0.3613 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.9248\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.94643\n",
      "197/197 [==============================] - 79s 400ms/step - loss: 0.3448 - accuracy: 0.9248 - val_loss: 0.3411 - val_accuracy: 0.9279 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9386\n",
      "Epoch 14: val_accuracy improved from 0.94643 to 0.94898, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 0.3001 - accuracy: 0.9386 - val_loss: 0.2760 - val_accuracy: 0.9490 - lr: 2.0000e-04\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.9458\n",
      "Epoch 15: val_accuracy did not improve from 0.94898\n",
      "197/197 [==============================] - 78s 397ms/step - loss: 0.2737 - accuracy: 0.9458 - val_loss: 0.2543 - val_accuracy: 0.9483 - lr: 2.0000e-04\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9505\n",
      "Epoch 16: val_accuracy did not improve from 0.94898\n",
      "197/197 [==============================] - 80s 405ms/step - loss: 0.2496 - accuracy: 0.9505 - val_loss: 0.2411 - val_accuracy: 0.9464 - lr: 2.0000e-04\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9491\n",
      "Epoch 17: val_accuracy did not improve from 0.94898\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 0.2390 - accuracy: 0.9491 - val_loss: 0.2368 - val_accuracy: 0.9490 - lr: 2.0000e-04\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9480\n",
      "Epoch 18: val_accuracy did not improve from 0.94898\n",
      "197/197 [==============================] - 78s 396ms/step - loss: 0.2302 - accuracy: 0.9480 - val_loss: 0.2416 - val_accuracy: 0.9439 - lr: 2.0000e-04\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9482\n",
      "Epoch 19: val_accuracy did not improve from 0.94898\n",
      "197/197 [==============================] - 79s 402ms/step - loss: 0.2242 - accuracy: 0.9482 - val_loss: 0.2257 - val_accuracy: 0.9483 - lr: 2.0000e-04\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9505\n",
      "Epoch 20: val_accuracy improved from 0.94898 to 0.95026, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 77s 392ms/step - loss: 0.2152 - accuracy: 0.9505 - val_loss: 0.2101 - val_accuracy: 0.9503 - lr: 2.0000e-04\n",
      "\n",
      "Phase 1 Best Validation Accuracy: 0.9503 at epoch 20\n",
      "Loading best weights from Phase 1 (resnet50_best_weights.h5)...\n",
      "\n",
      "ðŸ”¹ Phase 2: ResNet50 - Fine-tuning\n",
      "Unfreezing layers from index 143 ('conv5_block1_1_conv') onwards.\n",
      "  Keeping BN layer frozen: conv5_block1_1_bn\n",
      "  Keeping BN layer frozen: conv5_block1_2_bn\n",
      "  Keeping BN layer frozen: conv5_block1_0_bn\n",
      "  Keeping BN layer frozen: conv5_block1_3_bn\n",
      "  Keeping BN layer frozen: conv5_block2_1_bn\n",
      "  Keeping BN layer frozen: conv5_block2_2_bn\n",
      "  Keeping BN layer frozen: conv5_block2_3_bn\n",
      "  Keeping BN layer frozen: conv5_block3_1_bn\n",
      "  Keeping BN layer frozen: conv5_block3_2_bn\n",
      "  Keeping BN layer frozen: conv5_block3_3_bn\n",
      "\n",
      "--- Model Summary (Phase 2: Fine-tuning) ---\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " dense_head (Dense)             (None, 512)          1049088     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      " bn_head (BatchNormalization)   (None, 512)          2048        ['dense_head[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_head (Dropout)         (None, 512)          0           ['bn_head[0][0]']                \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 18)           9234        ['dropout_head[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,648,082\n",
      "Trainable params: 16,012,818\n",
      "Non-trainable params: 8,635,264\n",
      "__________________________________________________________________________________________________\n",
      "Starting fine-tuning for up to 40 epochs (total epochs: 60)...\n",
      "Epoch 21/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 12:35:56.621633: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9532"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 12:37:10.409810: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: val_accuracy improved from -inf to 0.94579, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 84s 405ms/step - loss: 0.2062 - accuracy: 0.9532 - val_loss: 0.2218 - val_accuracy: 0.9458 - lr: 1.0000e-05\n",
      "Epoch 22/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9563\n",
      "Epoch 22: val_accuracy improved from 0.94579 to 0.95472, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 79s 402ms/step - loss: 0.1950 - accuracy: 0.9563 - val_loss: 0.2178 - val_accuracy: 0.9547 - lr: 1.0000e-05\n",
      "Epoch 23/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9615\n",
      "Epoch 23: val_accuracy improved from 0.95472 to 0.95536, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.1825 - accuracy: 0.9615 - val_loss: 0.2078 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 24/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9636\n",
      "Epoch 24: val_accuracy improved from 0.95536 to 0.95599, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 81s 409ms/step - loss: 0.1756 - accuracy: 0.9636 - val_loss: 0.1940 - val_accuracy: 0.9560 - lr: 1.0000e-05\n",
      "Epoch 25/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9633\n",
      "Epoch 25: val_accuracy improved from 0.95599 to 0.95918, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 0.1700 - accuracy: 0.9633 - val_loss: 0.1875 - val_accuracy: 0.9592 - lr: 1.0000e-05\n",
      "Epoch 26/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9712\n",
      "Epoch 26: val_accuracy did not improve from 0.95918\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.1584 - accuracy: 0.9712 - val_loss: 0.1868 - val_accuracy: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 27/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9726\n",
      "Epoch 27: val_accuracy improved from 0.95918 to 0.96110, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 80s 407ms/step - loss: 0.1500 - accuracy: 0.9726 - val_loss: 0.1964 - val_accuracy: 0.9611 - lr: 1.0000e-05\n",
      "Epoch 28/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9734\n",
      "Epoch 28: val_accuracy did not improve from 0.96110\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.1465 - accuracy: 0.9734 - val_loss: 0.2032 - val_accuracy: 0.9579 - lr: 1.0000e-05\n",
      "Epoch 29/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9755\n",
      "Epoch 29: val_accuracy improved from 0.96110 to 0.96301, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 79s 400ms/step - loss: 0.1386 - accuracy: 0.9755 - val_loss: 0.2066 - val_accuracy: 0.9630 - lr: 1.0000e-05\n",
      "Epoch 30/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9758\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.96301\n",
      "197/197 [==============================] - 79s 403ms/step - loss: 0.1405 - accuracy: 0.9758 - val_loss: 0.1888 - val_accuracy: 0.9624 - lr: 1.0000e-05\n",
      "Epoch 31/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.9792\n",
      "Epoch 31: val_accuracy did not improve from 0.96301\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1299 - accuracy: 0.9792 - val_loss: 0.1868 - val_accuracy: 0.9630 - lr: 2.0000e-06\n",
      "Epoch 32/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9785\n",
      "Epoch 32: val_accuracy did not improve from 0.96301\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.1283 - accuracy: 0.9785 - val_loss: 0.1799 - val_accuracy: 0.9624 - lr: 2.0000e-06\n",
      "Epoch 33/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9825\n",
      "Epoch 33: val_accuracy did not improve from 0.96301\n",
      "197/197 [==============================] - 79s 400ms/step - loss: 0.1226 - accuracy: 0.9825 - val_loss: 0.1830 - val_accuracy: 0.9630 - lr: 2.0000e-06\n",
      "Epoch 34/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9820\n",
      "Epoch 34: val_accuracy did not improve from 0.96301\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 0.1212 - accuracy: 0.9820 - val_loss: 0.1869 - val_accuracy: 0.9617 - lr: 2.0000e-06\n",
      "Epoch 35/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9849\n",
      "Epoch 35: val_accuracy improved from 0.96301 to 0.96429, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 81s 410ms/step - loss: 0.1204 - accuracy: 0.9849 - val_loss: 0.1847 - val_accuracy: 0.9643 - lr: 2.0000e-06\n",
      "Epoch 36/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9809\n",
      "Epoch 36: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 79s 403ms/step - loss: 0.1256 - accuracy: 0.9809 - val_loss: 0.1794 - val_accuracy: 0.9643 - lr: 2.0000e-06\n",
      "Epoch 37/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9846\n",
      "Epoch 37: val_accuracy improved from 0.96429 to 0.96620, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1164 - accuracy: 0.9846 - val_loss: 0.1813 - val_accuracy: 0.9662 - lr: 2.0000e-06\n",
      "Epoch 38/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9830\n",
      "Epoch 38: val_accuracy did not improve from 0.96620\n",
      "197/197 [==============================] - 78s 397ms/step - loss: 0.1186 - accuracy: 0.9830 - val_loss: 0.1912 - val_accuracy: 0.9636 - lr: 2.0000e-06\n",
      "Epoch 39/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9863\n",
      "Epoch 39: val_accuracy did not improve from 0.96620\n",
      "197/197 [==============================] - 79s 401ms/step - loss: 0.1113 - accuracy: 0.9863 - val_loss: 0.1839 - val_accuracy: 0.9630 - lr: 2.0000e-06\n",
      "Epoch 40/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9860\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-07.\n",
      "\n",
      "Epoch 40: val_accuracy improved from 0.96620 to 0.96811, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1098 - accuracy: 0.9860 - val_loss: 0.1837 - val_accuracy: 0.9681 - lr: 2.0000e-06\n",
      "Epoch 41/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9866\n",
      "Epoch 41: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 80s 407ms/step - loss: 0.1129 - accuracy: 0.9866 - val_loss: 0.1816 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 42/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9846\n",
      "Epoch 42: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 82s 417ms/step - loss: 0.1121 - accuracy: 0.9846 - val_loss: 0.1803 - val_accuracy: 0.9681 - lr: 4.0000e-07\n",
      "Epoch 43/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9827\n",
      "Epoch 43: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1127 - accuracy: 0.9827 - val_loss: 0.1788 - val_accuracy: 0.9681 - lr: 4.0000e-07\n",
      "Epoch 44/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9849\n",
      "Epoch 44: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 83s 420ms/step - loss: 0.1135 - accuracy: 0.9849 - val_loss: 0.1787 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 45/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9854\n",
      "Epoch 45: val_accuracy improved from 0.96811 to 0.96875, saving model to resnet50_best_weights.h5\n",
      "197/197 [==============================] - 79s 403ms/step - loss: 0.1163 - accuracy: 0.9854 - val_loss: 0.1784 - val_accuracy: 0.9688 - lr: 4.0000e-07\n",
      "Epoch 46/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9839\n",
      "Epoch 46: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 81s 411ms/step - loss: 0.1145 - accuracy: 0.9839 - val_loss: 0.1783 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 47/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9835\n",
      "Epoch 47: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 79s 399ms/step - loss: 0.1164 - accuracy: 0.9835 - val_loss: 0.1762 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 48/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9862\n",
      "Epoch 48: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 82s 417ms/step - loss: 0.1116 - accuracy: 0.9862 - val_loss: 0.1766 - val_accuracy: 0.9668 - lr: 4.0000e-07\n",
      "Epoch 49/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.9885\n",
      "Epoch 49: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1087 - accuracy: 0.9885 - val_loss: 0.1776 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 50/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9843\n",
      "Epoch 50: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 406ms/step - loss: 0.1115 - accuracy: 0.9843 - val_loss: 0.1769 - val_accuracy: 0.9675 - lr: 4.0000e-07\n",
      "Epoch 51/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9860\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 408ms/step - loss: 0.1127 - accuracy: 0.9860 - val_loss: 0.1769 - val_accuracy: 0.9688 - lr: 4.0000e-07\n",
      "Epoch 52/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9871\n",
      "Epoch 52: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 405ms/step - loss: 0.1097 - accuracy: 0.9871 - val_loss: 0.1762 - val_accuracy: 0.9681 - lr: 1.0000e-07\n",
      "Epoch 53/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9857\n",
      "Epoch 53: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 83s 423ms/step - loss: 0.1134 - accuracy: 0.9857 - val_loss: 0.1760 - val_accuracy: 0.9681 - lr: 1.0000e-07\n",
      "Epoch 54/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9852\n",
      "Epoch 54: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 405ms/step - loss: 0.1106 - accuracy: 0.9852 - val_loss: 0.1766 - val_accuracy: 0.9675 - lr: 1.0000e-07\n",
      "Epoch 55/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9876\n",
      "Epoch 55: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 407ms/step - loss: 0.1104 - accuracy: 0.9876 - val_loss: 0.1766 - val_accuracy: 0.9668 - lr: 1.0000e-07\n",
      "Epoch 56/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9862\n",
      "Epoch 56: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 78s 398ms/step - loss: 0.1124 - accuracy: 0.9862 - val_loss: 0.1756 - val_accuracy: 0.9675 - lr: 1.0000e-07\n",
      "Epoch 57/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9866\n",
      "Epoch 57: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 79s 402ms/step - loss: 0.1102 - accuracy: 0.9866 - val_loss: 0.1754 - val_accuracy: 0.9681 - lr: 1.0000e-07\n",
      "Epoch 58/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9843\n",
      "Epoch 58: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 78s 398ms/step - loss: 0.1121 - accuracy: 0.9843 - val_loss: 0.1757 - val_accuracy: 0.9675 - lr: 1.0000e-07\n",
      "Epoch 59/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9862\n",
      "Epoch 59: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 80s 403ms/step - loss: 0.1110 - accuracy: 0.9862 - val_loss: 0.1751 - val_accuracy: 0.9675 - lr: 1.0000e-07\n",
      "Epoch 60/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.9868\n",
      "Epoch 60: val_accuracy did not improve from 0.96875\n",
      "197/197 [==============================] - 79s 400ms/step - loss: 0.1119 - accuracy: 0.9868 - val_loss: 0.1752 - val_accuracy: 0.9675 - lr: 1.0000e-07\n",
      "\n",
      "Loading best weights achieved during entire training...\n",
      "Loading best weights from resnet50_best_weights.h5 for final evaluation...\n",
      "\n",
      "Evaluating model with best weights on validation set:\n",
      " 3/49 [>.............................] - ETA: 1s - loss: 0.0693 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 13:29:19.129448: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 9s 184ms/step - loss: 0.1784 - accuracy: 0.9688\n",
      "Final Validation Loss: 0.1784\n",
      "Final Validation Accuracy: 0.9688\n",
      "\n",
      "ðŸŽ‰ Target accuracy reached! Final Validation Accuracy: 0.9688\n",
      "\n",
      "âœ… Best model saved as 'resnet50_final_best.h5'\n"
     ]
    }
   ],
   "source": [
    "# âœ… ResNet50 Training Script with Improvements for Accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "# Import the specific preprocessing function for ResNet\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.experimental import AdamW # Or tf.keras.optimizers if using older TF\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil # For splitting data\n",
    "\n",
    "# ðŸ”¹ Set seed for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ðŸ”¹ Dataset path (update this if needed)\n",
    "base_dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "\n",
    "train_dir = os.path.join(base_dataset_path, \"train\")\n",
    "val_dir = os.path.join(base_dataset_path, \"validation\")\n",
    "VAL_SPLIT = 0.2 # Use 20% of data for validation\n",
    "\n",
    "# ðŸ”¹ Helper Function to Split Data (Run this once if needed)\n",
    "def split_data(base_path, train_path, val_path, split_ratio=0.2):\n",
    "    # --- (This function is identical to the previous one) ---\n",
    "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
    "        print(\"Train/Validation directories already exist. Skipping split.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Creating train/validation split ({1-split_ratio:.0%}/{split_ratio:.0%}) in {base_path}...\")\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "    original_class_folders = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    if not original_class_folders:\n",
    "         print(f\"Error: No class subdirectories found directly inside '{base_path}'.\")\n",
    "         print(\"Please ensure class folders (e.g., 'ClassA', 'ClassB') are directly within the base path.\")\n",
    "         return # Stop if no class folders found\n",
    "\n",
    "    for class_name in original_class_folders:\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        # Create corresponding directories in train/val\n",
    "        train_class_dir = os.path.join(train_path, class_name)\n",
    "        val_class_dir = os.path.join(val_path, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_dir, exist_ok=True)\n",
    "\n",
    "        # List images and shuffle\n",
    "        images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
    "        if not images:\n",
    "            print(f\"Warning: No images found in {class_dir}\")\n",
    "            continue\n",
    "        np.random.shuffle(images) # Shuffle in place\n",
    "\n",
    "        # Split files\n",
    "        split_point = int(len(images) * (1 - split_ratio))\n",
    "        train_files = images[:split_point]\n",
    "        val_files = images[split_point:]\n",
    "\n",
    "        # Copy files\n",
    "        print(f\"  Splitting {class_name}: {len(train_files)} train, {len(val_files)} val\")\n",
    "        for f in train_files:\n",
    "             try:\n",
    "                shutil.copy2(os.path.join(class_dir, f), os.path.join(train_class_dir, f)) # copy2 preserves metadata\n",
    "             except Exception as e:\n",
    "                 print(f\"Error copying {f} to train: {e}\")\n",
    "        for f in val_files:\n",
    "            try:\n",
    "                shutil.copy2(os.path.join(class_dir, f), os.path.join(val_class_dir, f))\n",
    "            except Exception as e:\n",
    "                 print(f\"Error copying {f} to val: {e}\")\n",
    "    print(\"Data splitting complete.\")\n",
    "    print(f\"Train data in: {train_path}\")\n",
    "    print(f\"Validation data in: {val_path}\")\n",
    "\n",
    "\n",
    "# --- Run the data splitting function ---\n",
    "# Important: Make sure your base_dataset_path points to the directory containing class subfolders.\n",
    "original_data_path = base_dataset_path # Assumes class folders are directly inside this path\n",
    "split_data(original_data_path, train_dir, val_dir, split_ratio=VAL_SPLIT)\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ðŸ”¹ Data Augmentation & Generators\n",
    "IMG_SIZE = (224, 224) # Standard ResNet50 input size\n",
    "BATCH_SIZE = 32 # Adjust based on GPU memory\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # No rescale=1./255, use ResNet's preprocess_input instead\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2], # Still okay to use brightness adjustment\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation generator ONLY uses preprocess_input\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Check number of classes\n",
    "try:\n",
    "    num_classes = train_generator.num_classes\n",
    "    print(f\"Found {train_generator.samples} train images belonging to {num_classes} classes.\")\n",
    "    print(f\"Found {val_generator.samples} validation images belonging to {num_classes} classes.\")\n",
    "    if num_classes is None or num_classes == 0:\n",
    "        raise ValueError(\"No classes found. Check data directories.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing generators or finding classes: {e}\")\n",
    "    print(\"Please ensure 'train_dir' and 'val_dir' contain subdirectories for each class, and these subdirectories contain images.\")\n",
    "    exit() # Stop script if data isn't loaded correctly\n",
    "\n",
    "\n",
    "# ðŸ”¹ Load ResNet50\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False  # Freeze base initially\n",
    "\n",
    "# ðŸ”¹ Add classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001), name='dense_head')(x)\n",
    "x = BatchNormalization(name='bn_head')(x)\n",
    "x = Dropout(0.4, name='dropout_head')(x) # Adjusted dropout\n",
    "outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# ðŸ”¹ Compile model for Phase 1\n",
    "initial_lr = 1e-3\n",
    "optimizer_phase1 = AdamW(learning_rate=initial_lr, weight_decay=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase1,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 1: Frozen Base) ---\")\n",
    "model.summary()\n",
    "\n",
    "# ðŸ”¹ Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1) # Increased patience\n",
    "model_checkpoint = ModelCheckpoint('resnet50_best_weights.h5', # Changed filename\n",
    "                                   monitor='val_accuracy', save_best_only=True,\n",
    "                                   save_weights_only=True, verbose=1)\n",
    "\n",
    "callbacks_phase1 = [reduce_lr, early_stopping, model_checkpoint]\n",
    "\n",
    "# ðŸ”¹ PHASE 1: Training with frozen base\n",
    "print(\"\\nðŸ”¹ Phase 1: ResNet50 - Frozen base\")\n",
    "initial_epochs = 20 # Can adjust this\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks_phase1,\n",
    "    steps_per_epoch=max(1, train_generator.samples // BATCH_SIZE), # Ensure steps >= 1\n",
    "    validation_steps=max(1, val_generator.samples // BATCH_SIZE)   # Ensure steps >= 1\n",
    ")\n",
    "\n",
    "# Find the epoch with the best validation accuracy in phase 1\n",
    "if history_phase1 and 'val_accuracy' in history_phase1.history and history_phase1.history['val_accuracy']:\n",
    "    best_epoch_phase1 = np.argmax(history_phase1.history['val_accuracy'])\n",
    "    best_val_acc_phase1 = np.max(history_phase1.history['val_accuracy'])\n",
    "    print(f\"\\nPhase 1 Best Validation Accuracy: {best_val_acc_phase1:.4f} at epoch {best_epoch_phase1 + 1}\")\n",
    "else:\n",
    "    print(\"\\nWarning: No validation accuracy history found for Phase 1. Cannot determine best epoch.\")\n",
    "    best_val_acc_phase1 = 0 # Assign a default\n",
    "\n",
    "# Load the best weights found during Phase 1 before fine-tuning\n",
    "# Check if the weights file exists before loading\n",
    "best_weights_path = 'resnet50_best_weights.h5'\n",
    "if os.path.exists(best_weights_path) and best_val_acc_phase1 > 0:\n",
    "     print(f\"Loading best weights from Phase 1 ({best_weights_path})...\")\n",
    "     try:\n",
    "        model.load_weights(best_weights_path)\n",
    "     except Exception as e:\n",
    "         print(f\"Error loading weights: {e}. Continuing without loading.\")\n",
    "else:\n",
    "    print(\"Best weights file not found or no improvement in Phase 1. Proceeding with current weights for fine-tuning.\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ PHASE 2: Fine-tuning\n",
    "print(\"\\nðŸ”¹ Phase 2: ResNet50 - Fine-tuning\")\n",
    "\n",
    "# Unfreeze layers from the beginning of the last stage (conv5_block1)\n",
    "base_model.trainable = True\n",
    "fine_tune_from_layer = 'conv5_block1_1_conv' # Start fine-tuning from here\n",
    "unfreeze_from_index = None\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if layer.name == fine_tune_from_layer:\n",
    "        unfreeze_from_index = i\n",
    "        break\n",
    "\n",
    "if unfreeze_from_index is not None:\n",
    "    print(f\"Unfreezing layers from index {unfreeze_from_index} ('{fine_tune_from_layer}') onwards.\")\n",
    "    for layer in base_model.layers[:unfreeze_from_index]:\n",
    "        layer.trainable = False\n",
    "    # Keep Batch Normalization layers frozen during early fine-tuning\n",
    "    for layer in base_model.layers[unfreeze_from_index:]:\n",
    "         if isinstance(layer, BatchNormalization):\n",
    "             print(f\"  Keeping BN layer frozen: {layer.name}\")\n",
    "             layer.trainable = False # Keep BN frozen\n",
    "         else:\n",
    "             layer.trainable = True # Ensure others are trainable\n",
    "else:\n",
    "    print(f\"Warning: Layer '{fine_tune_from_layer}' not found. Unfreezing all base model layers.\")\n",
    "    # Fallback: keep all BN frozen if specific layer not found\n",
    "    for layer in base_model.layers:\n",
    "         if isinstance(layer, BatchNormalization):\n",
    "             layer.trainable = False\n",
    "\n",
    "\n",
    "# Recompile with a very low LR for fine-tuning\n",
    "fine_tune_lr = 1e-5\n",
    "optimizer_phase2 = AdamW(learning_rate=fine_tune_lr, weight_decay=1e-5)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase2,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 2: Fine-tuning) ---\")\n",
    "model.summary() # Show summary with updated trainable params\n",
    "\n",
    "# Adjust callbacks for fine-tuning phase\n",
    "reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1) # More patience\n",
    "early_stopping_ft = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1) # More patience\n",
    "model_checkpoint_ft = ModelCheckpoint('resnet50_best_weights.h5', # Continue saving best weights to the same file\n",
    "                                      monitor='val_accuracy', save_best_only=True,\n",
    "                                      save_weights_only=True, verbose=1)\n",
    "\n",
    "callbacks_phase2 = [reduce_lr_ft, early_stopping_ft, model_checkpoint_ft]\n",
    "\n",
    "\n",
    "# Train model further with fine-tuning\n",
    "total_epochs = 60 # Adjust total epochs as needed\n",
    "fine_tune_epochs = total_epochs - initial_epochs\n",
    "\n",
    "print(f\"Starting fine-tuning for up to {fine_tune_epochs} epochs (total epochs: {total_epochs})...\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs, # Resume epoch counting\n",
    "    callbacks=callbacks_phase2,\n",
    "    steps_per_epoch=max(1, train_generator.samples // BATCH_SIZE),\n",
    "    validation_steps=max(1, val_generator.samples // BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Evaluation after Fine-Tuning\n",
    "print(\"\\nLoading best weights achieved during entire training...\")\n",
    "# Load the absolute best weights saved during the whole process\n",
    "if os.path.exists(best_weights_path):\n",
    "    print(f\"Loading best weights from {best_weights_path} for final evaluation...\")\n",
    "    try:\n",
    "        model.load_weights(best_weights_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading final best weights: {e}. Evaluating with current weights.\")\n",
    "else:\n",
    "    print(\"Best weights file not found. Evaluating with final weights from training.\")\n",
    "\n",
    "\n",
    "print(\"\\nEvaluating model with best weights on validation set:\")\n",
    "# Ensure validation steps is at least 1 for evaluation\n",
    "eval_validation_steps = max(1, val_generator.samples // BATCH_SIZE)\n",
    "loss, accuracy = model.evaluate(val_generator, steps=eval_validation_steps)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "if accuracy >= 0.91:\n",
    "    print(f\"\\nðŸŽ‰ Target accuracy reached! Final Validation Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTarget accuracy of 0.91 not reached. Final Best Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Consider further experimentation (more epochs, different LR, adjust unfrozen layers, augmentation, etc.).\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ Save final model (architecture + best weights)\n",
    "final_model_path = \"resnet50_final_best.h5\"\n",
    "model.save(final_model_path)\n",
    "print(f\"\\nâœ… Best model saved as '{final_model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation directories ('train', 'validation') already exist in '/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset'. Skipping split.\n",
      "\n",
      "Creating Train Generator from: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/train\n",
      "Found 6320 images belonging to 18 classes.\n",
      "Creating Validation Generator from: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/validation\n",
      "Found 1587 images belonging to 18 classes.\n",
      "\n",
      "Found 6320 train images belonging to 18 classes.\n",
      "Found 1587 validation images belonging to 18 classes.\n",
      "\n",
      "--- Model Summary (Phase 1 - MobileNetV2 Frozen Base) ---\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_avg_pool (GlobalAverage  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " dense_head (Dense)             (None, 512)          655872      ['global_avg_pool[0][0]']        \n",
      "                                                                                                  \n",
      " bn_head (BatchNormalization)   (None, 512)          2048        ['dense_head[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_head (Dropout)         (None, 512)          0           ['bn_head[0][0]']                \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 18)           9234        ['dropout_head[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,925,138\n",
      "Trainable params: 666,130\n",
      "Non-trainable params: 2,259,008\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "ðŸ”¹ Phase 1: MobileNetV2 - Frozen base\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:46:08.954873: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 1.1425 - accuracy: 0.8406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:47:16.236475: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89605, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 78s 382ms/step - loss: 1.1425 - accuracy: 0.8406 - val_loss: 0.8900 - val_accuracy: 0.8960 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.8170 - accuracy: 0.8946\n",
      "Epoch 2: val_accuracy improved from 0.89605 to 0.89796, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 0.8170 - accuracy: 0.8946 - val_loss: 0.7533 - val_accuracy: 0.8980 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6782 - accuracy: 0.9003\n",
      "Epoch 3: val_accuracy improved from 0.89796 to 0.91135, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.6782 - accuracy: 0.9003 - val_loss: 0.6158 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.9016\n",
      "Epoch 4: val_accuracy did not improve from 0.91135\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.5920 - accuracy: 0.9016 - val_loss: 0.5697 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.9028\n",
      "Epoch 5: val_accuracy improved from 0.91135 to 0.91709, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.5188 - accuracy: 0.9028 - val_loss: 0.4644 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4678 - accuracy: 0.9070\n",
      "Epoch 6: val_accuracy improved from 0.91709 to 0.92347, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.4678 - accuracy: 0.9070 - val_loss: 0.4427 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.9117\n",
      "Epoch 7: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.4396 - accuracy: 0.9117 - val_loss: 0.4829 - val_accuracy: 0.8916 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.9082\n",
      "Epoch 8: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 383ms/step - loss: 0.4126 - accuracy: 0.9082 - val_loss: 0.3848 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.9116\n",
      "Epoch 9: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 74s 373ms/step - loss: 0.3972 - accuracy: 0.9116 - val_loss: 0.3762 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.9138\n",
      "Epoch 10: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.3816 - accuracy: 0.9138 - val_loss: 0.3867 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.9090\n",
      "Epoch 11: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 74s 378ms/step - loss: 0.3789 - accuracy: 0.9090 - val_loss: 0.3604 - val_accuracy: 0.9171 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.9143\n",
      "Epoch 12: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 73s 369ms/step - loss: 0.3528 - accuracy: 0.9143 - val_loss: 0.3564 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.9105\n",
      "Epoch 13: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 74s 376ms/step - loss: 0.3618 - accuracy: 0.9105 - val_loss: 0.3503 - val_accuracy: 0.9216 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.9106\n",
      "Epoch 14: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.3610 - accuracy: 0.9106 - val_loss: 0.3376 - val_accuracy: 0.9120 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3504 - accuracy: 0.9135\n",
      "Epoch 15: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.3504 - accuracy: 0.9135 - val_loss: 0.3470 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.9113\n",
      "Epoch 16: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 76s 383ms/step - loss: 0.3474 - accuracy: 0.9113 - val_loss: 0.3170 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.9152\n",
      "Epoch 17: val_accuracy did not improve from 0.92347\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.3399 - accuracy: 0.9152 - val_loss: 0.3061 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.9140\n",
      "Epoch 18: val_accuracy improved from 0.92347 to 0.92666, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 77s 392ms/step - loss: 0.3308 - accuracy: 0.9140 - val_loss: 0.3217 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.9106\n",
      "Epoch 19: val_accuracy did not improve from 0.92666\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 0.3383 - accuracy: 0.9106 - val_loss: 0.3228 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9221\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.92666\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.3178 - accuracy: 0.9221 - val_loss: 0.3235 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "\n",
      "Phase 1 Best Validation Accuracy: 0.9267 at epoch 18\n",
      "Loading best weights from Phase 1 (mobilenetv2_best_weights.h5)...\n",
      "\n",
      "ðŸ”¹ Phase 2: MobileNetV2 - Fine-tuning\n",
      "Unfreezing layers from index 116 ('block_13_expand') onwards.\n",
      "  Keeping BN layer frozen: block_13_expand_BN\n",
      "  Keeping BN layer frozen: block_13_depthwise_BN\n",
      "  Keeping BN layer frozen: block_13_project_BN\n",
      "  Keeping BN layer frozen: block_14_expand_BN\n",
      "  Keeping BN layer frozen: block_14_depthwise_BN\n",
      "  Keeping BN layer frozen: block_14_project_BN\n",
      "  Keeping BN layer frozen: block_15_expand_BN\n",
      "  Keeping BN layer frozen: block_15_depthwise_BN\n",
      "  Keeping BN layer frozen: block_15_project_BN\n",
      "  Keeping BN layer frozen: block_16_expand_BN\n",
      "  Keeping BN layer frozen: block_16_depthwise_BN\n",
      "  Keeping BN layer frozen: block_16_project_BN\n",
      "  Keeping BN layer frozen: Conv_1_bn\n",
      "\n",
      "--- Model Summary (Phase 2: Fine-tuning MobileNetV2) ---\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_avg_pool (GlobalAverage  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " dense_head (Dense)             (None, 512)          655872      ['global_avg_pool[0][0]']        \n",
      "                                                                                                  \n",
      " bn_head (BatchNormalization)   (None, 512)          2048        ['dense_head[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_head (Dropout)         (None, 512)          0           ['bn_head[0][0]']                \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 18)           9234        ['dropout_head[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,925,138\n",
      "Trainable params: 2,329,490\n",
      "Non-trainable params: 595,648\n",
      "__________________________________________________________________________________________________\n",
      "Starting fine-tuning for up to 40 epochs (total epochs: 60)...\n",
      "Epoch 21/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 10:11:14.391134: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 10:12:20.714246: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21: val_accuracy improved from -inf to 0.91390, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 77s 377ms/step - loss: 0.3059 - accuracy: 0.9248 - val_loss: 0.3245 - val_accuracy: 0.9139 - lr: 2.0000e-05\n",
      "Epoch 22/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.9315\n",
      "Epoch 22: val_accuracy improved from 0.91390 to 0.92921, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 72s 368ms/step - loss: 0.2790 - accuracy: 0.9315 - val_loss: 0.2842 - val_accuracy: 0.9292 - lr: 2.0000e-05\n",
      "Epoch 23/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.9356\n",
      "Epoch 23: val_accuracy did not improve from 0.92921\n",
      "197/197 [==============================] - 76s 383ms/step - loss: 0.2624 - accuracy: 0.9356 - val_loss: 0.3025 - val_accuracy: 0.9267 - lr: 2.0000e-05\n",
      "Epoch 24/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9418\n",
      "Epoch 24: val_accuracy improved from 0.92921 to 0.93686, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.2528 - accuracy: 0.9418 - val_loss: 0.2557 - val_accuracy: 0.9369 - lr: 2.0000e-05\n",
      "Epoch 25/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9431\n",
      "Epoch 25: val_accuracy improved from 0.93686 to 0.94069, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.2486 - accuracy: 0.9431 - val_loss: 0.2527 - val_accuracy: 0.9407 - lr: 2.0000e-05\n",
      "Epoch 26/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.9515\n",
      "Epoch 26: val_accuracy did not improve from 0.94069\n",
      "197/197 [==============================] - 77s 389ms/step - loss: 0.2266 - accuracy: 0.9515 - val_loss: 0.2842 - val_accuracy: 0.9286 - lr: 2.0000e-05\n",
      "Epoch 27/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9499\n",
      "Epoch 27: val_accuracy did not improve from 0.94069\n",
      "197/197 [==============================] - 74s 376ms/step - loss: 0.2246 - accuracy: 0.9499 - val_loss: 0.2898 - val_accuracy: 0.9292 - lr: 2.0000e-05\n",
      "Epoch 28/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.9528\n",
      "Epoch 28: val_accuracy did not improve from 0.94069\n",
      "197/197 [==============================] - 74s 375ms/step - loss: 0.2156 - accuracy: 0.9528 - val_loss: 0.2751 - val_accuracy: 0.9330 - lr: 2.0000e-05\n",
      "Epoch 29/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9542\n",
      "Epoch 29: val_accuracy improved from 0.94069 to 0.94579, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 73s 370ms/step - loss: 0.2135 - accuracy: 0.9542 - val_loss: 0.2511 - val_accuracy: 0.9458 - lr: 2.0000e-05\n",
      "Epoch 30/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9569\n",
      "Epoch 30: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 74s 373ms/step - loss: 0.2034 - accuracy: 0.9569 - val_loss: 0.3409 - val_accuracy: 0.9196 - lr: 2.0000e-05\n",
      "Epoch 31/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9561\n",
      "Epoch 31: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 72s 364ms/step - loss: 0.2046 - accuracy: 0.9561 - val_loss: 0.2351 - val_accuracy: 0.9445 - lr: 2.0000e-05\n",
      "Epoch 32/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9610\n",
      "Epoch 32: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 73s 368ms/step - loss: 0.1946 - accuracy: 0.9610 - val_loss: 0.2623 - val_accuracy: 0.9375 - lr: 2.0000e-05\n",
      "Epoch 33/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9598\n",
      "Epoch 33: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 74s 377ms/step - loss: 0.1898 - accuracy: 0.9598 - val_loss: 0.2519 - val_accuracy: 0.9452 - lr: 2.0000e-05\n",
      "Epoch 34/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9649\n",
      "Epoch 34: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.1824 - accuracy: 0.9649 - val_loss: 0.2607 - val_accuracy: 0.9401 - lr: 2.0000e-05\n",
      "Epoch 35/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.9666\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.94579\n",
      "197/197 [==============================] - 76s 384ms/step - loss: 0.1732 - accuracy: 0.9666 - val_loss: 0.3095 - val_accuracy: 0.9324 - lr: 2.0000e-05\n",
      "Epoch 36/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9685\n",
      "Epoch 36: val_accuracy improved from 0.94579 to 0.95855, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 76s 384ms/step - loss: 0.1656 - accuracy: 0.9685 - val_loss: 0.2170 - val_accuracy: 0.9585 - lr: 4.0000e-06\n",
      "Epoch 37/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9736\n",
      "Epoch 37: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.1557 - accuracy: 0.9736 - val_loss: 0.2190 - val_accuracy: 0.9528 - lr: 4.0000e-06\n",
      "Epoch 38/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.9738\n",
      "Epoch 38: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 72s 366ms/step - loss: 0.1545 - accuracy: 0.9738 - val_loss: 0.2191 - val_accuracy: 0.9547 - lr: 4.0000e-06\n",
      "Epoch 39/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9719\n",
      "Epoch 39: val_accuracy improved from 0.95855 to 0.96173, saving model to mobilenetv2_best_weights.h5\n",
      "197/197 [==============================] - 73s 370ms/step - loss: 0.1560 - accuracy: 0.9719 - val_loss: 0.2060 - val_accuracy: 0.9617 - lr: 4.0000e-06\n",
      "Epoch 40/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9768\n",
      "Epoch 40: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 72s 366ms/step - loss: 0.1481 - accuracy: 0.9768 - val_loss: 0.2113 - val_accuracy: 0.9560 - lr: 4.0000e-06\n",
      "Epoch 41/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9776\n",
      "Epoch 41: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.1476 - accuracy: 0.9776 - val_loss: 0.2212 - val_accuracy: 0.9566 - lr: 4.0000e-06\n",
      "Epoch 42/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.9768\n",
      "Epoch 42: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.1476 - accuracy: 0.9768 - val_loss: 0.2110 - val_accuracy: 0.9573 - lr: 4.0000e-06\n",
      "Epoch 43/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9758\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 77s 390ms/step - loss: 0.1472 - accuracy: 0.9758 - val_loss: 0.2210 - val_accuracy: 0.9560 - lr: 4.0000e-06\n",
      "Epoch 44/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.9763\n",
      "Epoch 44: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.1459 - accuracy: 0.9763 - val_loss: 0.2190 - val_accuracy: 0.9560 - lr: 8.0000e-07\n",
      "Epoch 45/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9771\n",
      "Epoch 45: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 74s 375ms/step - loss: 0.1423 - accuracy: 0.9771 - val_loss: 0.2125 - val_accuracy: 0.9554 - lr: 8.0000e-07\n",
      "Epoch 46/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9755\n",
      "Epoch 46: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.1461 - accuracy: 0.9755 - val_loss: 0.2229 - val_accuracy: 0.9541 - lr: 8.0000e-07\n",
      "Epoch 47/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9792\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 73s 371ms/step - loss: 0.1398 - accuracy: 0.9792 - val_loss: 0.2165 - val_accuracy: 0.9554 - lr: 8.0000e-07\n",
      "Epoch 48/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.9785\n",
      "Epoch 48: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 74s 377ms/step - loss: 0.1386 - accuracy: 0.9785 - val_loss: 0.2159 - val_accuracy: 0.9547 - lr: 1.6000e-07\n",
      "Epoch 49/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9788\n",
      "Epoch 49: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 72s 366ms/step - loss: 0.1418 - accuracy: 0.9788 - val_loss: 0.2158 - val_accuracy: 0.9547 - lr: 1.6000e-07\n",
      "Epoch 50/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1445 - accuracy: 0.9752\n",
      "Epoch 50: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.1445 - accuracy: 0.9752 - val_loss: 0.2172 - val_accuracy: 0.9547 - lr: 1.6000e-07\n",
      "Epoch 51/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9781\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 384ms/step - loss: 0.1425 - accuracy: 0.9781 - val_loss: 0.2169 - val_accuracy: 0.9547 - lr: 1.6000e-07\n",
      "Epoch 52/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.9769\n",
      "Epoch 52: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.1433 - accuracy: 0.9769 - val_loss: 0.2173 - val_accuracy: 0.9547 - lr: 1.0000e-07\n",
      "Epoch 53/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9788\n",
      "Epoch 53: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.1390 - accuracy: 0.9788 - val_loss: 0.2164 - val_accuracy: 0.9554 - lr: 1.0000e-07\n",
      "Epoch 54/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9792\n",
      "Epoch 54: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 75s 383ms/step - loss: 0.1392 - accuracy: 0.9792 - val_loss: 0.2165 - val_accuracy: 0.9554 - lr: 1.0000e-07\n",
      "Epoch 55/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1413 - accuracy: 0.9788\n",
      "Epoch 55: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.1413 - accuracy: 0.9788 - val_loss: 0.2169 - val_accuracy: 0.9554 - lr: 1.0000e-07\n",
      "Epoch 56/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9787\n",
      "Epoch 56: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 74s 373ms/step - loss: 0.1392 - accuracy: 0.9787 - val_loss: 0.2168 - val_accuracy: 0.9554 - lr: 1.0000e-07\n",
      "Epoch 57/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.9828\n",
      "Epoch 57: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 76s 385ms/step - loss: 0.1363 - accuracy: 0.9828 - val_loss: 0.2173 - val_accuracy: 0.9547 - lr: 1.0000e-07\n",
      "Epoch 58/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9792\n",
      "Epoch 58: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 73s 369ms/step - loss: 0.1377 - accuracy: 0.9792 - val_loss: 0.2174 - val_accuracy: 0.9554 - lr: 1.0000e-07\n",
      "Epoch 59/60\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9771Restoring model weights from the end of the best epoch: 39.\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.96173\n",
      "197/197 [==============================] - 73s 371ms/step - loss: 0.1419 - accuracy: 0.9771 - val_loss: 0.2164 - val_accuracy: 0.9560 - lr: 1.0000e-07\n",
      "Epoch 59: early stopping\n",
      "\n",
      "Loading best weights achieved during entire training...\n",
      "Loading best weights from mobilenetv2_best_weights.h5 for final evaluation...\n",
      "\n",
      "Evaluating model with best weights on validation set:\n",
      " 3/49 [>.............................] - ETA: 1s - loss: 0.0809 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 10:59:38.186605: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 10s 209ms/step - loss: 0.2060 - accuracy: 0.9617\n",
      "Final Validation Loss: 0.2060\n",
      "Final Validation Accuracy: 0.9617\n",
      "\n",
      "ðŸŽ‰ Target accuracy reached! Final Validation Accuracy: 0.9617\n",
      "\n",
      "âœ… Best model saved as 'mobilenetv2_final_best.h5'\n"
     ]
    }
   ],
   "source": [
    "# âœ… MobileNetV2 Training Script with Improvements for Accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "# Import the specific preprocessing function for MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers.experimental import AdamW # Or tf.keras.optimizers if using older TF\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil # For splitting data\n",
    "import sys # To exit script gracefully\n",
    "\n",
    "# ðŸ”¹ Set seed for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ðŸ”¹ Dataset path (<<<<< VERIFY THIS PATH AND STRUCTURE >>>>>)\n",
    "base_dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "train_dir = os.path.join(base_dataset_path, \"train\")\n",
    "val_dir = os.path.join(base_dataset_path, \"validation\")\n",
    "VAL_SPLIT = 0.2 # Use 20% of data for validation\n",
    "\n",
    "# ðŸ”¹ Helper Function to Split Data (Identical to previous scripts)\n",
    "def split_data(base_path, train_path, val_path, split_ratio=0.2):\n",
    "    # --- (Assume the improved split_data function from the previous answer is here) ---\n",
    "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
    "        print(f\"Train/Validation directories ('{os.path.basename(train_path)}', '{os.path.basename(val_path)}') already exist in '{base_path}'. Skipping split.\")\n",
    "        if not any(os.scandir(train_path)) or not any(os.scandir(val_path)):\n",
    "             print(\"WARNING: Existing train/validation directories appear empty. Consider deleting them and re-running if data is missing.\")\n",
    "        return True\n",
    "    print(f\"Attempting to create train/validation split ({1-split_ratio:.0%}/{split_ratio:.0%}) from '{base_path}'...\")\n",
    "    try:\n",
    "        potential_class_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: The specified base_dataset_path '{base_path}' was not found.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not list directories in '{base_path}': {e}\")\n",
    "        return False\n",
    "    class_folders = [d for d in potential_class_dirs if d.lower() not in ['train', 'validation']]\n",
    "    if not class_folders:\n",
    "         print(f\"ERROR: No class subdirectories found directly inside '{base_path}'.\")\n",
    "         print(f\"       Found items: {os.listdir(base_path)}\")\n",
    "         return False\n",
    "    print(f\"Found class folders: {class_folders}\")\n",
    "    os.makedirs(train_path, exist_ok=True); os.makedirs(val_path, exist_ok=True)\n",
    "    print(f\"Created directories: '{train_path}' and '{val_path}'\")\n",
    "    total_copied_train = 0; total_copied_val = 0\n",
    "    for class_name in class_folders:\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        train_class_dir = os.path.join(train_path, class_name); val_class_dir = os.path.join(val_path, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True); os.makedirs(val_class_dir, exist_ok=True)\n",
    "        try:\n",
    "            images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        except Exception as e: print(f\"Warning: Could not read files in {class_dir}: {e}\"); continue\n",
    "        if not images: print(f\"Warning: No image files found in source directory: {class_dir}\"); continue\n",
    "        np.random.shuffle(images)\n",
    "        split_point = int(len(images) * (1 - split_ratio)); train_files = images[:split_point]; val_files = images[split_point:]\n",
    "        print(f\"  Splitting '{class_name}': {len(images)} images found -> {len(train_files)} train, {len(val_files)} val\")\n",
    "        copied_train_count = 0\n",
    "        for f in train_files:\n",
    "            src_file = os.path.join(class_dir, f); dst_file = os.path.join(train_class_dir, f)\n",
    "            try: shutil.copy2(src_file, dst_file); copied_train_count += 1\n",
    "            except Exception as e: print(f\"    ERROR copying {src_file} to {dst_file}: {e}\")\n",
    "        total_copied_train += copied_train_count\n",
    "        copied_val_count = 0\n",
    "        for f in val_files:\n",
    "            src_file = os.path.join(class_dir, f); dst_file = os.path.join(val_class_dir, f)\n",
    "            try: shutil.copy2(src_file, dst_file); copied_val_count += 1\n",
    "            except Exception as e: print(f\"    ERROR copying {src_file} to {dst_file}: {e}\")\n",
    "        total_copied_val += copied_val_count\n",
    "        if copied_train_count != len(train_files) or copied_val_count != len(val_files): print(f\"  Warning: Mismatch in expected vs copied files for class '{class_name}'\")\n",
    "    print(f\"Data splitting complete. Copied {total_copied_train} train images, {total_copied_val} validation images.\")\n",
    "    if total_copied_train == 0 or total_copied_val == 0: print(\"ERROR: Failed to copy any images.\"); return False\n",
    "    return True\n",
    "\n",
    "# --- Run the data splitting function ---\n",
    "if not split_data(base_dataset_path, train_dir, val_dir, split_ratio=VAL_SPLIT):\n",
    "    print(\"\\nExiting script due to data splitting errors.\")\n",
    "    sys.exit(1) # Exit if splitting failed critically\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ðŸ”¹ Data Augmentation & Generators\n",
    "IMG_SIZE = (224, 224) # Standard MobileNetV2 input size\n",
    "BATCH_SIZE = 32 # MobileNetV2 is usually less memory intensive, 32 or 64 might work\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Use MobileNetV2 preprocessing\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation generator ONLY uses MobileNetV2 preprocess_input\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print(f\"\\nCreating Train Generator from: {train_dir}\")\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=SEED\n",
    "    )\n",
    "except Exception as e: print(f\"ERROR: Failed to create train_generator: {e}\"); sys.exit(1)\n",
    "\n",
    "print(f\"Creating Validation Generator from: {val_dir}\")\n",
    "try:\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "except Exception as e: print(f\"ERROR: Failed to create val_generator: {e}\"); sys.exit(1)\n",
    "\n",
    "# Check number of classes AND samples\n",
    "num_classes = train_generator.num_classes\n",
    "train_samples = train_generator.samples\n",
    "val_samples = val_generator.samples\n",
    "\n",
    "print(f\"\\nFound {train_samples} train images belonging to {num_classes} classes.\")\n",
    "print(f\"Found {val_samples} validation images belonging to {num_classes} classes.\")\n",
    "\n",
    "if train_samples == 0 or val_samples == 0 or num_classes <= 1: # Need at least 2 classes\n",
    "    print(\"\\nERROR: Generators reported 0 images or <= 1 class. Check data directories and splitting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ðŸ”¹ Load MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), alpha=1.0) # alpha controls width\n",
    "base_model.trainable = False  # Freeze base initially\n",
    "\n",
    "# ðŸ”¹ Add classification head (similar structure often works well)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001), name='dense_head')(x) # Adjust units/regularization if needed\n",
    "x = BatchNormalization(name='bn_head')(x)\n",
    "x = Dropout(0.3, name='dropout_head')(x) # Adjust dropout rate if needed (maybe slightly less than VGG/EfficientNet)\n",
    "outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# ðŸ”¹ Compile model for Phase 1\n",
    "initial_lr = 1e-3\n",
    "optimizer_phase1 = AdamW(learning_rate=initial_lr, weight_decay=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase1,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 1 - MobileNetV2 Frozen Base) ---\")\n",
    "model.summary()\n",
    "\n",
    "# ðŸ”¹ Callbacks\n",
    "model_weights_file = 'mobilenetv2_best_weights.h5'\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1) # Moderate patience\n",
    "model_checkpoint = ModelCheckpoint(model_weights_file, monitor='val_accuracy', save_best_only=True,\n",
    "                                   save_weights_only=True, verbose=1)\n",
    "\n",
    "callbacks_phase1 = [reduce_lr, early_stopping, model_checkpoint]\n",
    "\n",
    "# Calculate steps, ensuring they are at least 1\n",
    "steps_per_epoch = max(1, train_samples // BATCH_SIZE)\n",
    "validation_steps = max(1, val_samples // BATCH_SIZE)\n",
    "\n",
    "# ðŸ”¹ PHASE 1: Training with frozen base\n",
    "print(\"\\nðŸ”¹ Phase 1: MobileNetV2 - Frozen base\")\n",
    "initial_epochs = 20 # MobileNet head might converge reasonably fast\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks_phase1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "# Find the epoch with the best validation accuracy in phase 1\n",
    "best_val_acc_phase1 = 0\n",
    "if history_phase1 and 'val_accuracy' in history_phase1.history and history_phase1.history['val_accuracy']:\n",
    "    best_epoch_phase1 = np.argmax(history_phase1.history['val_accuracy'])\n",
    "    best_val_acc_phase1 = np.max(history_phase1.history['val_accuracy'])\n",
    "    print(f\"\\nPhase 1 Best Validation Accuracy: {best_val_acc_phase1:.4f} at epoch {best_epoch_phase1 + 1}\")\n",
    "else:\n",
    "    print(\"\\nWarning: No validation accuracy history found for Phase 1.\")\n",
    "\n",
    "# Load the best weights found during Phase 1 before fine-tuning\n",
    "if os.path.exists(model_weights_file) and best_val_acc_phase1 > 0:\n",
    "     print(f\"Loading best weights from Phase 1 ({model_weights_file})...\")\n",
    "     try: model.load_weights(model_weights_file)\n",
    "     except Exception as e: print(f\"Error loading weights: {e}. Continuing without loading.\")\n",
    "else:\n",
    "    print(\"Best weights file not found or no improvement in Phase 1. Proceeding with current weights.\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ PHASE 2: Fine-tuning\n",
    "print(\"\\nðŸ”¹ Phase 2: MobileNetV2 - Fine-tuning\")\n",
    "\n",
    "# Unfreeze layers from around block 13 or 14 onwards (MobileNetV2 has 16 blocks total)\n",
    "base_model.trainable = True\n",
    "fine_tune_from_layer_name = 'block_13_expand' # Experiment with 'block_14_expand' or earlier/later blocks\n",
    "unfreeze_from_index = None\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if layer.name == fine_tune_from_layer_name:\n",
    "        unfreeze_from_index = i\n",
    "        break\n",
    "\n",
    "if unfreeze_from_index is not None:\n",
    "    print(f\"Unfreezing layers from index {unfreeze_from_index} ('{fine_tune_from_layer_name}') onwards.\")\n",
    "    for layer in base_model.layers[:unfreeze_from_index]:\n",
    "        layer.trainable = False\n",
    "    # Keep Batch Normalization layers frozen in the unfrozen part\n",
    "    for layer in base_model.layers[unfreeze_from_index:]:\n",
    "         if isinstance(layer, BatchNormalization):\n",
    "             print(f\"  Keeping BN layer frozen: {layer.name}\")\n",
    "             layer.trainable = False\n",
    "         else:\n",
    "            # Ensure non-BN layers in the unfrozen part are trainable\n",
    "             layer.trainable = True\n",
    "else:\n",
    "    print(f\"Warning: Layer '{fine_tune_from_layer_name}' not found. Unfreezing all base layers.\")\n",
    "    # Apply BN freezing logic to all base layers if specific layer not found\n",
    "    for layer in base_model.layers:\n",
    "         if isinstance(layer, BatchNormalization):\n",
    "             layer.trainable = False\n",
    "\n",
    "\n",
    "# Recompile with a very low LR for fine-tuning\n",
    "fine_tune_lr = 2e-5 # Start slightly higher than VGG/EfficientNet maybe, e.g., 1e-5 or 2e-5\n",
    "optimizer_phase2 = AdamW(learning_rate=fine_tune_lr, weight_decay=1e-5)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase2,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 2: Fine-tuning MobileNetV2) ---\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for fine-tuning\n",
    "reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1)\n",
    "early_stopping_ft = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint_ft = ModelCheckpoint(model_weights_file, monitor='val_accuracy', save_best_only=True,\n",
    "                                      save_weights_only=True, verbose=1) # Continue saving best\n",
    "\n",
    "callbacks_phase2 = [reduce_lr_ft, early_stopping_ft, model_checkpoint_ft]\n",
    "\n",
    "# Train model further with fine-tuning\n",
    "total_epochs = 60 # Adjust total epochs\n",
    "fine_tune_epochs = total_epochs - initial_epochs\n",
    "\n",
    "print(f\"Starting fine-tuning for up to {fine_tune_epochs} epochs (total epochs: {total_epochs})...\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs, # Resume epoch counting\n",
    "    callbacks=callbacks_phase2,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Evaluation after Fine-Tuning\n",
    "print(\"\\nLoading best weights achieved during entire training...\")\n",
    "if os.path.exists(model_weights_file):\n",
    "    print(f\"Loading best weights from {model_weights_file} for final evaluation...\")\n",
    "    try: model.load_weights(model_weights_file)\n",
    "    except Exception as e: print(f\"Error loading final best weights: {e}. Evaluating with current weights.\")\n",
    "else:\n",
    "    print(\"Best weights file not found. Evaluating with final weights from training.\")\n",
    "\n",
    "print(\"\\nEvaluating model with best weights on validation set:\")\n",
    "eval_validation_steps = max(1, val_samples // BATCH_SIZE)\n",
    "loss, accuracy = model.evaluate(val_generator, steps=eval_validation_steps)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "if accuracy >= 0.91:\n",
    "    print(f\"\\nðŸŽ‰ Target accuracy reached! Final Validation Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTarget accuracy of 0.91 not reached. Final Best Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Consider further experimentation (epochs, LR, unfrozen layers, head architecture, augmentation).\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ Save final model (architecture + best weights)\n",
    "final_model_path = \"mobilenetv2_final_best.h5\"\n",
    "model.save(final_model_path)\n",
    "print(f\"\\nâœ… Best model saved as '{final_model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validation directories ('train', 'validation') already exist in '/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset'. Skipping split.\n",
      "\n",
      "Creating Train Generator from: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/train\n",
      "Found 6320 images belonging to 18 classes.\n",
      "Creating Validation Generator from: /data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset/validation\n",
      "Found 1587 images belonging to 18 classes.\n",
      "\n",
      "Found 6320 train images belonging to 18 classes.\n",
      "Found 1587 validation images belonging to 18 classes.\n",
      "\n",
      "--- Model Summary (Phase 1 - VGG16 Frozen Base) ---\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_avg_pool (GlobalAver  (None, 512)              0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " fc1_head (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " bn_head (BatchNormalization  (None, 512)              2048      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_head (Dropout)      (None, 512)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,988,626\n",
      "Trainable params: 272,914\n",
      "Non-trainable params: 14,715,712\n",
      "_________________________________________________________________\n",
      "\n",
      "ðŸ”¹ Phase 1: VGG16 - Frozen base\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 08:42:39.771900: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 1.0945 - accuracy: 0.8015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 08:43:43.850216: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86607, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 375ms/step - loss: 1.0945 - accuracy: 0.8015 - val_loss: 0.8208 - val_accuracy: 0.8661 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.8771\n",
      "Epoch 2: val_accuracy improved from 0.86607 to 0.90242, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 73s 373ms/step - loss: 0.7463 - accuracy: 0.8771 - val_loss: 0.6532 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.8901\n",
      "Epoch 3: val_accuracy did not improve from 0.90242\n",
      "197/197 [==============================] - 74s 374ms/step - loss: 0.6507 - accuracy: 0.8901 - val_loss: 0.6631 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.8949\n",
      "Epoch 4: val_accuracy did not improve from 0.90242\n",
      "197/197 [==============================] - 75s 383ms/step - loss: 0.5734 - accuracy: 0.8949 - val_loss: 0.6308 - val_accuracy: 0.8699 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.5360 - accuracy: 0.8968\n",
      "Epoch 5: val_accuracy did not improve from 0.90242\n",
      "197/197 [==============================] - 73s 371ms/step - loss: 0.5360 - accuracy: 0.8968 - val_loss: 0.4927 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4777 - accuracy: 0.9109\n",
      "Epoch 6: val_accuracy improved from 0.90242 to 0.91837, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 77s 388ms/step - loss: 0.4777 - accuracy: 0.9109 - val_loss: 0.4533 - val_accuracy: 0.9184 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.9116\n",
      "Epoch 7: val_accuracy did not improve from 0.91837\n",
      "197/197 [==============================] - 73s 369ms/step - loss: 0.4513 - accuracy: 0.9116 - val_loss: 0.4848 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.9078\n",
      "Epoch 8: val_accuracy improved from 0.91837 to 0.91964, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 77s 391ms/step - loss: 0.4366 - accuracy: 0.9078 - val_loss: 0.3993 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.9066\n",
      "Epoch 9: val_accuracy improved from 0.91964 to 0.92283, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 76s 385ms/step - loss: 0.4164 - accuracy: 0.9066 - val_loss: 0.4063 - val_accuracy: 0.9228 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.4101 - accuracy: 0.9060\n",
      "Epoch 10: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 75s 379ms/step - loss: 0.4101 - accuracy: 0.9060 - val_loss: 0.4300 - val_accuracy: 0.8973 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.9114\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 0.3902 - accuracy: 0.9114 - val_loss: 0.4521 - val_accuracy: 0.8865 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.9205\n",
      "Epoch 12: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.3566 - accuracy: 0.9205 - val_loss: 0.3756 - val_accuracy: 0.9120 - lr: 2.0000e-04\n",
      "Epoch 13/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3396 - accuracy: 0.9276\n",
      "Epoch 13: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.3396 - accuracy: 0.9276 - val_loss: 0.3851 - val_accuracy: 0.9139 - lr: 2.0000e-04\n",
      "Epoch 14/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.9295\n",
      "Epoch 14: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 76s 385ms/step - loss: 0.3317 - accuracy: 0.9295 - val_loss: 0.3649 - val_accuracy: 0.9203 - lr: 2.0000e-04\n",
      "Epoch 15/15\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.9276\n",
      "Epoch 15: val_accuracy did not improve from 0.92283\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.3256 - accuracy: 0.9276 - val_loss: 0.3599 - val_accuracy: 0.9171 - lr: 2.0000e-04\n",
      "\n",
      "Phase 1 Best Validation Accuracy: 0.9228 at epoch 9\n",
      "Loading best weights from Phase 1 (vgg16_best_weights.h5)...\n",
      "\n",
      "ðŸ”¹ Phase 2: VGG16 - Fine-tuning\n",
      "Unfreezing layers from index 15 ('block5_conv1') onwards.\n",
      "\n",
      "--- Model Summary (Phase 2: Fine-tuning VGG16) ---\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_avg_pool (GlobalAver  (None, 512)              0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " fc1_head (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " bn_head (BatchNormalization  (None, 512)              2048      \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_head (Dropout)      (None, 512)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 18)                9234      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,988,626\n",
      "Trainable params: 7,352,338\n",
      "Non-trainable params: 7,636,288\n",
      "_________________________________________________________________\n",
      "Starting fine-tuning for up to 35 epochs (total epochs: 50)...\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:01:26.701441: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.9254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:02:32.391239: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16: val_accuracy improved from -inf to 0.94260, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 372ms/step - loss: 0.3700 - accuracy: 0.9254 - val_loss: 0.3441 - val_accuracy: 0.9426 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.9375\n",
      "Epoch 17: val_accuracy did not improve from 0.94260\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 0.3361 - accuracy: 0.9375 - val_loss: 0.3631 - val_accuracy: 0.9292 - lr: 1.0000e-05\n",
      "Epoch 18/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.9477\n",
      "Epoch 18: val_accuracy improved from 0.94260 to 0.94834, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.3170 - accuracy: 0.9477 - val_loss: 0.3337 - val_accuracy: 0.9483 - lr: 1.0000e-05\n",
      "Epoch 19/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9531\n",
      "Epoch 19: val_accuracy did not improve from 0.94834\n",
      "197/197 [==============================] - 76s 388ms/step - loss: 0.3001 - accuracy: 0.9531 - val_loss: 0.3327 - val_accuracy: 0.9458 - lr: 1.0000e-05\n",
      "Epoch 20/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.9520\n",
      "Epoch 20: val_accuracy improved from 0.94834 to 0.95344, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 77s 389ms/step - loss: 0.2922 - accuracy: 0.9520 - val_loss: 0.3132 - val_accuracy: 0.9534 - lr: 1.0000e-05\n",
      "Epoch 21/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.9575\n",
      "Epoch 21: val_accuracy improved from 0.95344 to 0.95855, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 74s 377ms/step - loss: 0.2807 - accuracy: 0.9575 - val_loss: 0.2980 - val_accuracy: 0.9585 - lr: 1.0000e-05\n",
      "Epoch 22/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.9577\n",
      "Epoch 22: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 0.2784 - accuracy: 0.9577 - val_loss: 0.2894 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 23/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9620\n",
      "Epoch 23: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 76s 384ms/step - loss: 0.2650 - accuracy: 0.9620 - val_loss: 0.3049 - val_accuracy: 0.9547 - lr: 1.0000e-05\n",
      "Epoch 24/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.9628\n",
      "Epoch 24: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 77s 392ms/step - loss: 0.2594 - accuracy: 0.9628 - val_loss: 0.3058 - val_accuracy: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 25/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9668\n",
      "Epoch 25: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.2543 - accuracy: 0.9668 - val_loss: 0.3040 - val_accuracy: 0.9541 - lr: 1.0000e-05\n",
      "Epoch 26/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9671\n",
      "Epoch 26: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 383ms/step - loss: 0.2471 - accuracy: 0.9671 - val_loss: 0.2863 - val_accuracy: 0.9515 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.9703\n",
      "Epoch 27: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 382ms/step - loss: 0.2404 - accuracy: 0.9703 - val_loss: 0.2894 - val_accuracy: 0.9560 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9707\n",
      "Epoch 28: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 76s 384ms/step - loss: 0.2382 - accuracy: 0.9707 - val_loss: 0.2847 - val_accuracy: 0.9541 - lr: 1.0000e-05\n",
      "Epoch 29/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9730\n",
      "Epoch 29: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.2296 - accuracy: 0.9730 - val_loss: 0.2878 - val_accuracy: 0.9503 - lr: 1.0000e-05\n",
      "Epoch 30/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.9742\n",
      "Epoch 30: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.2212 - accuracy: 0.9742 - val_loss: 0.2945 - val_accuracy: 0.9547 - lr: 1.0000e-05\n",
      "Epoch 31/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.9723\n",
      "Epoch 31: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.2295 - accuracy: 0.9723 - val_loss: 0.3234 - val_accuracy: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9768\n",
      "Epoch 32: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 73s 373ms/step - loss: 0.2167 - accuracy: 0.9768 - val_loss: 0.2765 - val_accuracy: 0.9560 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9758\n",
      "Epoch 33: val_accuracy did not improve from 0.95855\n",
      "197/197 [==============================] - 78s 395ms/step - loss: 0.2162 - accuracy: 0.9758 - val_loss: 0.2865 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.9768\n",
      "Epoch 34: val_accuracy improved from 0.95855 to 0.96046, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.2155 - accuracy: 0.9768 - val_loss: 0.2736 - val_accuracy: 0.9605 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9779\n",
      "Epoch 35: val_accuracy did not improve from 0.96046\n",
      "197/197 [==============================] - 77s 388ms/step - loss: 0.2090 - accuracy: 0.9779 - val_loss: 0.3007 - val_accuracy: 0.9528 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9798\n",
      "Epoch 36: val_accuracy did not improve from 0.96046\n",
      "197/197 [==============================] - 95s 481ms/step - loss: 0.2073 - accuracy: 0.9798 - val_loss: 0.2754 - val_accuracy: 0.9605 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.9817\n",
      "Epoch 37: val_accuracy did not improve from 0.96046\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.2001 - accuracy: 0.9817 - val_loss: 0.2689 - val_accuracy: 0.9585 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9804\n",
      "Epoch 38: val_accuracy did not improve from 0.96046\n",
      "197/197 [==============================] - 77s 389ms/step - loss: 0.1971 - accuracy: 0.9804 - val_loss: 0.2886 - val_accuracy: 0.9560 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9782\n",
      "Epoch 39: val_accuracy improved from 0.96046 to 0.96110, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.2010 - accuracy: 0.9782 - val_loss: 0.2637 - val_accuracy: 0.9611 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.9803\n",
      "Epoch 40: val_accuracy improved from 0.96110 to 0.96429, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 75s 380ms/step - loss: 0.1972 - accuracy: 0.9803 - val_loss: 0.2564 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1869 - accuracy: 0.9851\n",
      "Epoch 41: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 76s 384ms/step - loss: 0.1869 - accuracy: 0.9851 - val_loss: 0.2755 - val_accuracy: 0.9598 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9835\n",
      "Epoch 42: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.1887 - accuracy: 0.9835 - val_loss: 0.2739 - val_accuracy: 0.9598 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9836\n",
      "Epoch 43: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 78s 394ms/step - loss: 0.1879 - accuracy: 0.9836 - val_loss: 0.2576 - val_accuracy: 0.9624 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9828\n",
      "Epoch 44: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 75s 381ms/step - loss: 0.1821 - accuracy: 0.9828 - val_loss: 0.2513 - val_accuracy: 0.9630 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9846\n",
      "Epoch 45: val_accuracy did not improve from 0.96429\n",
      "197/197 [==============================] - 74s 375ms/step - loss: 0.1772 - accuracy: 0.9846 - val_loss: 0.2759 - val_accuracy: 0.9592 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9858\n",
      "Epoch 46: val_accuracy improved from 0.96429 to 0.96811, saving model to vgg16_best_weights.h5\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.1772 - accuracy: 0.9858 - val_loss: 0.2671 - val_accuracy: 0.9681 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9876\n",
      "Epoch 47: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 77s 390ms/step - loss: 0.1715 - accuracy: 0.9876 - val_loss: 0.2458 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9857\n",
      "Epoch 48: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 76s 387ms/step - loss: 0.1720 - accuracy: 0.9857 - val_loss: 0.2768 - val_accuracy: 0.9585 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1638 - accuracy: 0.9892\n",
      "Epoch 49: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 75s 378ms/step - loss: 0.1638 - accuracy: 0.9892 - val_loss: 0.2499 - val_accuracy: 0.9649 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "197/197 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9887\n",
      "Epoch 50: val_accuracy did not improve from 0.96811\n",
      "197/197 [==============================] - 76s 386ms/step - loss: 0.1640 - accuracy: 0.9887 - val_loss: 0.2518 - val_accuracy: 0.9592 - lr: 1.0000e-05\n",
      "\n",
      "Loading best weights achieved during entire training...\n",
      "Loading best weights from vgg16_best_weights.h5 for final evaluation...\n",
      "\n",
      "Evaluating model with best weights on validation set:\n",
      " 3/49 [>.............................] - ETA: 1s - loss: 0.1344 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 09:45:56.681525: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 11s 220ms/step - loss: 0.2671 - accuracy: 0.9681\n",
      "Final Validation Loss: 0.2671\n",
      "Final Validation Accuracy: 0.9681\n",
      "\n",
      "ðŸŽ‰ Target accuracy reached! Final Validation Accuracy: 0.9681\n",
      "\n",
      "âœ… Best model saved as 'vgg16_final_best.h5'\n"
     ]
    }
   ],
   "source": [
    "# âœ… VGG16 Training Script with Improvements for Accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "# Import the specific preprocessing function for VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers.experimental import AdamW # Or tf.keras.optimizers if using older TF\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil # For splitting data\n",
    "import sys # To exit script gracefully\n",
    "\n",
    "# ðŸ”¹ Set seed for reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ðŸ”¹ Dataset path (<<<<< VERIFY THIS PATH AND STRUCTURE >>>>>)\n",
    "base_dataset_path = r\"/data/mpstme-aruja/Farm-Aid/Farm-Aid Dataset/Capstone Dataset\"\n",
    "train_dir = os.path.join(base_dataset_path, \"train\")\n",
    "val_dir = os.path.join(base_dataset_path, \"validation\")\n",
    "VAL_SPLIT = 0.2 # Use 20% of data for validation\n",
    "\n",
    "# ðŸ”¹ Helper Function to Split Data (Identical to previous scripts)\n",
    "def split_data(base_path, train_path, val_path, split_ratio=0.2):\n",
    "    # --- (Assume the improved split_data function from the previous answer is here) ---\n",
    "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
    "        print(f\"Train/Validation directories ('{os.path.basename(train_path)}', '{os.path.basename(val_path)}') already exist in '{base_path}'. Skipping split.\")\n",
    "        if not any(os.scandir(train_path)) or not any(os.scandir(val_path)):\n",
    "             print(\"WARNING: Existing train/validation directories appear empty. Consider deleting them and re-running if data is missing.\")\n",
    "        return True\n",
    "    print(f\"Attempting to create train/validation split ({1-split_ratio:.0%}/{split_ratio:.0%}) from '{base_path}'...\")\n",
    "    try:\n",
    "        potential_class_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: The specified base_dataset_path '{base_path}' was not found.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Could not list directories in '{base_path}': {e}\")\n",
    "        return False\n",
    "    class_folders = [d for d in potential_class_dirs if d.lower() not in ['train', 'validation']]\n",
    "    if not class_folders:\n",
    "         print(f\"ERROR: No class subdirectories found directly inside '{base_path}'.\")\n",
    "         print(f\"       Found items: {os.listdir(base_path)}\")\n",
    "         return False\n",
    "    print(f\"Found class folders: {class_folders}\")\n",
    "    os.makedirs(train_path, exist_ok=True); os.makedirs(val_path, exist_ok=True)\n",
    "    print(f\"Created directories: '{train_path}' and '{val_path}'\")\n",
    "    total_copied_train = 0; total_copied_val = 0\n",
    "    for class_name in class_folders:\n",
    "        class_dir = os.path.join(base_path, class_name)\n",
    "        train_class_dir = os.path.join(train_path, class_name); val_class_dir = os.path.join(val_path, class_name)\n",
    "        os.makedirs(train_class_dir, exist_ok=True); os.makedirs(val_class_dir, exist_ok=True)\n",
    "        try:\n",
    "            images = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "        except Exception as e: print(f\"Warning: Could not read files in {class_dir}: {e}\"); continue\n",
    "        if not images: print(f\"Warning: No image files found in source directory: {class_dir}\"); continue\n",
    "        np.random.shuffle(images)\n",
    "        split_point = int(len(images) * (1 - split_ratio)); train_files = images[:split_point]; val_files = images[split_point:]\n",
    "        print(f\"  Splitting '{class_name}': {len(images)} images found -> {len(train_files)} train, {len(val_files)} val\")\n",
    "        copied_train_count = 0\n",
    "        for f in train_files:\n",
    "            src_file = os.path.join(class_dir, f); dst_file = os.path.join(train_class_dir, f)\n",
    "            try: shutil.copy2(src_file, dst_file); copied_train_count += 1\n",
    "            except Exception as e: print(f\"    ERROR copying {src_file} to {dst_file}: {e}\")\n",
    "        total_copied_train += copied_train_count\n",
    "        copied_val_count = 0\n",
    "        for f in val_files:\n",
    "            src_file = os.path.join(class_dir, f); dst_file = os.path.join(val_class_dir, f)\n",
    "            try: shutil.copy2(src_file, dst_file); copied_val_count += 1\n",
    "            except Exception as e: print(f\"    ERROR copying {src_file} to {dst_file}: {e}\")\n",
    "        total_copied_val += copied_val_count\n",
    "        if copied_train_count != len(train_files) or copied_val_count != len(val_files): print(f\"  Warning: Mismatch in expected vs copied files for class '{class_name}'\")\n",
    "    print(f\"Data splitting complete. Copied {total_copied_train} train images, {total_copied_val} validation images.\")\n",
    "    if total_copied_train == 0 or total_copied_val == 0: print(\"ERROR: Failed to copy any images.\"); return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# --- Run the data splitting function ---\n",
    "if not split_data(base_dataset_path, train_dir, val_dir, split_ratio=VAL_SPLIT):\n",
    "    print(\"\\nExiting script due to data splitting errors.\")\n",
    "    sys.exit(1) # Exit if splitting failed critically\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ðŸ”¹ Data Augmentation & Generators\n",
    "IMG_SIZE = (224, 224) # Standard VGG16 input size\n",
    "BATCH_SIZE = 32 # Adjust based on GPU memory (VGG16 can be memory intensive)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input, # Use VGG16 preprocessing\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "    # Removed brightness range, less common with VGG preprocess_input, can add back if needed\n",
    ")\n",
    "\n",
    "# Validation generator ONLY uses VGG16 preprocess_input\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print(f\"\\nCreating Train Generator from: {train_dir}\")\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=SEED\n",
    "    )\n",
    "except Exception as e: print(f\"ERROR: Failed to create train_generator: {e}\"); sys.exit(1)\n",
    "\n",
    "print(f\"Creating Validation Generator from: {val_dir}\")\n",
    "try:\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "except Exception as e: print(f\"ERROR: Failed to create val_generator: {e}\"); sys.exit(1)\n",
    "\n",
    "# Check number of classes AND samples\n",
    "num_classes = train_generator.num_classes\n",
    "train_samples = train_generator.samples\n",
    "val_samples = val_generator.samples\n",
    "\n",
    "print(f\"\\nFound {train_samples} train images belonging to {num_classes} classes.\")\n",
    "print(f\"Found {val_samples} validation images belonging to {num_classes} classes.\")\n",
    "\n",
    "if train_samples == 0 or val_samples == 0 or num_classes <= 1: # Need at least 2 classes\n",
    "    print(\"\\nERROR: Generators reported 0 images or <= 1 class. Check data directories and splitting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ðŸ”¹ Load VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "base_model.trainable = False  # Freeze base initially\n",
    "\n",
    "# ðŸ”¹ Add classification head\n",
    "# VGG output is not pooled by default, need Flatten or GAP\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='global_avg_pool')(x) # Or Flatten() - GAP often works better against overfitting\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.001), name='fc1_head')(x) # Regularization might be important for VGG\n",
    "x = BatchNormalization(name='bn_head')(x) # Add BN for stability\n",
    "x = Dropout(0.5, name='dropout_head')(x) # Increase dropout for VGG\n",
    "outputs = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# ðŸ”¹ Compile model for Phase 1\n",
    "initial_lr = 1e-3 # May need to be slightly lower for VGG (e.g., 5e-4) if unstable\n",
    "optimizer_phase1 = AdamW(learning_rate=initial_lr, weight_decay=1e-4)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase1,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 1 - VGG16 Frozen Base) ---\")\n",
    "model.summary()\n",
    "\n",
    "# ðŸ”¹ Callbacks\n",
    "model_weights_file = 'vgg16_best_weights.h5'\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "# Increased patience slightly for VGG as it might take longer to stabilize\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(model_weights_file, monitor='val_accuracy', save_best_only=True,\n",
    "                                   save_weights_only=True, verbose=1)\n",
    "\n",
    "callbacks_phase1 = [reduce_lr, early_stopping, model_checkpoint]\n",
    "\n",
    "# Calculate steps, ensuring they are at least 1\n",
    "steps_per_epoch = max(1, train_samples // BATCH_SIZE)\n",
    "validation_steps = max(1, val_samples // BATCH_SIZE)\n",
    "\n",
    "# ðŸ”¹ PHASE 1: Training with frozen base\n",
    "print(\"\\nðŸ”¹ Phase 1: VGG16 - Frozen base\")\n",
    "initial_epochs = 15 # VGG head might train faster or slower, adjust as needed\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks_phase1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "# Find the epoch with the best validation accuracy in phase 1\n",
    "best_val_acc_phase1 = 0\n",
    "if history_phase1 and 'val_accuracy' in history_phase1.history and history_phase1.history['val_accuracy']:\n",
    "    best_epoch_phase1 = np.argmax(history_phase1.history['val_accuracy'])\n",
    "    best_val_acc_phase1 = np.max(history_phase1.history['val_accuracy'])\n",
    "    print(f\"\\nPhase 1 Best Validation Accuracy: {best_val_acc_phase1:.4f} at epoch {best_epoch_phase1 + 1}\")\n",
    "else:\n",
    "    print(\"\\nWarning: No validation accuracy history found for Phase 1.\")\n",
    "\n",
    "# Load the best weights found during Phase 1 before fine-tuning\n",
    "if os.path.exists(model_weights_file) and best_val_acc_phase1 > 0:\n",
    "     print(f\"Loading best weights from Phase 1 ({model_weights_file})...\")\n",
    "     try: model.load_weights(model_weights_file)\n",
    "     except Exception as e: print(f\"Error loading weights: {e}. Continuing without loading.\")\n",
    "else:\n",
    "    print(\"Best weights file not found or no improvement in Phase 1. Proceeding with current weights.\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ PHASE 2: Fine-tuning\n",
    "print(\"\\nðŸ”¹ Phase 2: VGG16 - Fine-tuning\")\n",
    "\n",
    "# Unfreeze the top convolutional block (block5)\n",
    "base_model.trainable = True\n",
    "fine_tune_from_layer_name = 'block5_conv1'\n",
    "unfreeze_from_index = None\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    if layer.name == fine_tune_from_layer_name:\n",
    "        unfreeze_from_index = i\n",
    "        break\n",
    "\n",
    "if unfreeze_from_index is not None:\n",
    "    print(f\"Unfreezing layers from index {unfreeze_from_index} ('{fine_tune_from_layer_name}') onwards.\")\n",
    "    for layer in base_model.layers[:unfreeze_from_index]:\n",
    "        layer.trainable = False\n",
    "    # VGG16 base doesn't have Batch Norm layers to worry about freezing\n",
    "else:\n",
    "    print(f\"Warning: Layer '{fine_tune_from_layer_name}' not found. Unfreezing all base layers.\")\n",
    "    # No specific BN logic needed here for VGG base\n",
    "\n",
    "\n",
    "# Recompile with a very low LR for fine-tuning\n",
    "fine_tune_lr = 1e-5 # Crucial to use a low LR\n",
    "optimizer_phase2 = AdamW(learning_rate=fine_tune_lr, weight_decay=1e-5)\n",
    "model.compile(\n",
    "    optimizer=optimizer_phase2,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Summary (Phase 2: Fine-tuning VGG16) ---\")\n",
    "model.summary()\n",
    "\n",
    "# Callbacks for fine-tuning (adjust patience)\n",
    "reduce_lr_ft = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-7, verbose=1)\n",
    "early_stopping_ft = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, verbose=1) # More patience for fine-tuning\n",
    "model_checkpoint_ft = ModelCheckpoint(model_weights_file, monitor='val_accuracy', save_best_only=True,\n",
    "                                      save_weights_only=True, verbose=1) # Continue saving best\n",
    "\n",
    "callbacks_phase2 = [reduce_lr_ft, early_stopping_ft, model_checkpoint_ft]\n",
    "\n",
    "# Train model further with fine-tuning\n",
    "total_epochs = 50 # Adjust total epochs as needed for VGG\n",
    "fine_tune_epochs = total_epochs - initial_epochs\n",
    "\n",
    "print(f\"Starting fine-tuning for up to {fine_tune_epochs} epochs (total epochs: {total_epochs})...\")\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=initial_epochs, # Resume epoch counting\n",
    "    callbacks=callbacks_phase2,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n",
    "\n",
    "# ðŸ”¹ Evaluation after Fine-Tuning\n",
    "print(\"\\nLoading best weights achieved during entire training...\")\n",
    "if os.path.exists(model_weights_file):\n",
    "    print(f\"Loading best weights from {model_weights_file} for final evaluation...\")\n",
    "    try: model.load_weights(model_weights_file)\n",
    "    except Exception as e: print(f\"Error loading final best weights: {e}. Evaluating with current weights.\")\n",
    "else:\n",
    "    print(\"Best weights file not found. Evaluating with final weights from training.\")\n",
    "\n",
    "print(\"\\nEvaluating model with best weights on validation set:\")\n",
    "eval_validation_steps = max(1, val_samples // BATCH_SIZE)\n",
    "loss, accuracy = model.evaluate(val_generator, steps=eval_validation_steps)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "if accuracy >= 0.91:\n",
    "    print(f\"\\nðŸŽ‰ Target accuracy reached! Final Validation Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"\\nTarget accuracy of 0.91 not reached. Final Best Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Consider further experimentation (epochs, LR, unfrozen layers [e.g., block4_conv1], regularization, augmentation).\")\n",
    "\n",
    "\n",
    "# ðŸ”¹ Save final model (architecture + best weights)\n",
    "final_model_path = \"vgg16_final_best.h5\"\n",
    "model.save(final_model_path)\n",
    "print(f\"\\nâœ… Best model saved as '{final_model_path}'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
